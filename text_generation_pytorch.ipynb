{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tnrange, tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "nitz_texts.txt\n",
      "**************************************************\n",
      "ny_articles.tar.gz\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import common.workshop\n",
    "\n",
    "common.workshop.download_text_generation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nitz_texts.txt\tny_articles.tar.gz\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./text-generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
      "ny_articles/\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
      "ny_articles/._ArticlesApril2018.csv.gz\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
      "ny_articles/ArticlesApril2018.csv.gz\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
      "ny_articles/._ArticlesFeb2018.csv.gz\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
      "ny_articles/ArticlesFeb2018.csv.gz\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
      "ny_articles/._CommentsApril2018.csv.gz\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
      "ny_articles/CommentsApril2018.csv.gz\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
      "ny_articles/._CommentsFeb2018.csv\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
      "ny_articles/CommentsFeb2018.csv\n"
     ]
    }
   ],
   "source": [
    "!cd ./text-generation && tar -xzvf ny_articles.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ArticlesApril2018.csv.gz  CommentsApril2018.csv.gz\r\n",
      "ArticlesFeb2018.csv.gz\t  CommentsFeb2018.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./text-generation/ny_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comments.txt  nitz_texts.txt  ny_articles  ny_articles.tar.gz\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./text-generation/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nitz texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRN_FILE = \"./text-generation/nitz_texts.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build vocab and data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_file(path):\n",
    "    with open(path, 'r') as fl:\n",
    "        return fl.read().replace('\\n', '')\n",
    "\n",
    "        \n",
    "def build_vocab(text):\n",
    "    s = set(text)\n",
    "    itos, stoi = [], {}\n",
    "    for ind,symb in enumerate(s):\n",
    "        itos.append(symb)\n",
    "        stoi[symb]=ind\n",
    "    return itos, stoi\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text = read_file(TRN_FILE)\n",
    "\n",
    "idx2text, text2idx = build_vocab(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def to_idx(text):\n",
    "    return np.array([text2idx[symb] for symb in text])\n",
    "    \n",
    "def to_text(nums):\n",
    "    return ''.join([idx2text[num] for num in nums])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41 80 15 32  7  1 15 50 10 41]\n",
      "PREFACESUP\n"
     ]
    }
   ],
   "source": [
    "\n",
    "idx_arr = to_idx(text[0:10])\n",
    "\n",
    "text_arr = to_text(idx_arr)\n",
    "\n",
    "print(idx_arr)\n",
    "print(text_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DataLoader:\n",
    "    def __init__(self, path, batch_size, time_step):\n",
    "        self.text = self.read_file(path)\n",
    "        self.vocab = self.build_vocab()\n",
    "        self.data = self.to_num()\n",
    "        self.batch_index = 0\n",
    "        self.batch_size = batch_size\n",
    "        self.time_step = time_step\n",
    "        self.n_batches = len(self.data)//(batch_size*time_step)\n",
    "        \n",
    "        \n",
    "    \n",
    "def batches_generator(batch_size, text, seq_length):\n",
    "    \n",
    "    batch_ind = 0\n",
    "    \n",
    "    data = to_idx(text)\n",
    "    \n",
    "    #\n",
    "    num_batches = len(data)//(batch_size*seq_length)\n",
    "    \n",
    "    for num_batch in range(0, num_batches):\n",
    "\n",
    "        x = data[batch_size * num_batch * seq_length : batch_size * (num_batch+1) * seq_length]\n",
    "        y = data[batch_size * num_batch * seq_length +1 : batch_size * (num_batch+1) * seq_length + 1]\n",
    "\n",
    "        x = x.reshape(-1,seq_length)\n",
    "        y = y.reshape(-1,seq_length)\n",
    "        yield x,y\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 30)\n",
      "(32, 30)\n",
      "PREFACESUPPOSING that Truth is\n",
      "REFACESUPPOSING that Truth is \n"
     ]
    }
   ],
   "source": [
    "\n",
    "x,y = next(batches_generator(32, text,30))\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "\n",
    "print(to_text(x[0]))\n",
    "print(to_text(y[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wod embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 10, 30])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 128\n",
    "seq_length = 10\n",
    "emb_size = 30\n",
    "vocab_size = len(text2idx)\n",
    "\n",
    "batch_iter = iter(batches_generator(batch_size, text, seq_length))\n",
    "input_seq, output_seq = next(batch_iter)\n",
    "\n",
    "emb = nn.Embedding(vocab_size, emb_size)\n",
    "\n",
    "input_tensor = torch.from_numpy(input_seq)\n",
    "\n",
    "print(emb(input_tensor).shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lang model: RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LangModel(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size, hidden_size, batch_size):\n",
    "        super(LangModel, self).__init__()\n",
    "        self.emedding_layer = nn.Embedding(vocab_size, emb_size)\n",
    "        self.rnn_layer = nn.RNN(emb_size, hidden_size)\n",
    "        self.linear_layer = nn.Linear(hidden_size, vocab_size)\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.hidden_params = self.init_hidden(batch_size)\n",
    "        \n",
    "    def forward(self, input_tensor):\n",
    "        # Retrieve batch size\n",
    "        batch_size = input_tensor[0].size(0)\n",
    "        \n",
    "        if self.hidden_params.size(1) != batch_size: \n",
    "            self.hidden_params = self.init_hidden(batch_size)\n",
    "        \n",
    "        emb_tensor = self.emedding_layer(input_tensor)\n",
    "        output_tensor, next_hidden = self.rnn_layer(emb_tensor, self.hidden_params)\n",
    "        \n",
    "        return F.log_softmax(self.linear_layer(output_tensor), dim = -1).view(-1, self.vocab_size)\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(1, batch_size, self.hidden_size).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def construct_model(vocab_size, emb_size, hidden_size, batch_size):\n",
    "    model = LangModel(vocab_size, emb_size, hidden_size, batch_size)\n",
    "    model = model.to(device)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Lang model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def construct_tensor(numpy_arr):\n",
    "    tensor = torch.from_numpy(numpy_arr)\n",
    "    tensor = tensor.to(device)\n",
    "    return tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-4.6953, -4.7072, -4.6130,  ..., -4.2085, -4.6164, -4.3639],\n",
      "        [-4.4384, -4.8323, -4.1699,  ..., -4.3219, -4.4645, -4.2140],\n",
      "        [-5.0325, -5.0747, -4.5080,  ..., -4.6630, -4.2402, -3.8481],\n",
      "        ...,\n",
      "        [-4.4583, -4.1439, -3.5896,  ..., -5.2715, -3.9107, -3.7906],\n",
      "        [-4.1524, -4.3446, -4.0038,  ..., -5.0785, -4.1973, -4.5735],\n",
      "        [-4.5551, -4.4597, -4.0915,  ..., -5.4896, -3.8273, -4.5114]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward>)\n",
      "torch.Size([32, 10]) torch.Size([320, 83])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vocab_size = len(text2idx)\n",
    "emb_size = 32 \n",
    "hidden_size = 16 \n",
    "batch_size = 32\n",
    "seq_length = 10\n",
    "\n",
    "\n",
    "model = construct_model(vocab_size, emb_size, hidden_size, batch_size)\n",
    "\n",
    "input_vector, output_vector = next(batches_generator(batch_size, text, seq_length))\n",
    "\n",
    "input_tensor = construct_tensor(input_vector)\n",
    "\n",
    "\n",
    "output_tensor = model(input_tensor)\n",
    "\n",
    "print(output_tensor)\n",
    "print(input_tensor.shape, output_tensor.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lstm Lang model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "??nn.LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class LstmLangModel(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size, hidden_size, batch_size, rnn_layers):\n",
    "        super(LstmLangModel, self).__init__()\n",
    "        \n",
    "        self.rnn_layers = rnn_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vocab_size = vocab_size\n",
    "        \n",
    "        self.embed_layer = nn.Embedding(vocab_size, emb_size)\n",
    "        self.lstm_layer = nn.LSTM(emb_size, hidden_size, \n",
    "                                  rnn_layers, dropout = 0.5,\n",
    "                                  bidirectional = False, \n",
    "                                  batch_first = True)\n",
    "        \n",
    "        self.lin1_layer = nn.Linear(hidden_size, hidden_size)\n",
    "        self.lin2_layer = nn.Linear(hidden_size, vocab_size)\n",
    "        \n",
    "        self.hidden, self.cell = self.init_hidden(batch_size)\n",
    "        \n",
    "    def forward(self, input_tensor):\n",
    "        batch_size = input_tensor.shape[0]\n",
    "        \n",
    "        if self.hidden.size(1) != batch_size: \n",
    "            self.hidden, self.cell = self.init_hidden(batch_size)\n",
    "            \n",
    "#         pdb.set_trace()\n",
    "        embed_tensor = self.embed_layer(input_tensor)\n",
    "        \n",
    "        output_tensor, h_tuple = self.lstm_layer(embed_tensor, (self.hidden, self.cell))\n",
    "        self.hidden.data, self.cell.data = h_tuple[0].data, h_tuple[1].data\n",
    "        \n",
    "        output_tensor = F.relu(self.lin1_layer(output_tensor))\n",
    "        return F.log_softmax(self.lin2_layer(output_tensor), dim = -1).view(-1, self.vocab_size)\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return (\n",
    "            torch.zeros(self.rnn_layers, batch_size, self.hidden_size).to(device),\n",
    "            torch.zeros(self.rnn_layers, batch_size, self.hidden_size).to(device)\n",
    "               )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-4.1063, -4.3922, -4.2959,  ..., -4.4662, -4.1292, -4.2375],\n",
      "        [-4.1049, -4.3996, -4.2887,  ..., -4.4711, -4.1277, -4.2412],\n",
      "        [-4.1189, -4.4102, -4.2922,  ..., -4.4717, -4.1280, -4.2306],\n",
      "        ...,\n",
      "        [-4.1212, -4.4159, -4.2920,  ..., -4.4615, -4.1287, -4.2264],\n",
      "        [-4.1148, -4.4119, -4.2931,  ..., -4.4592, -4.1263, -4.2289],\n",
      "        [-4.1104, -4.4056, -4.2943,  ..., -4.4594, -4.1322, -4.2293]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward>)\n",
      "torch.Size([32, 10]) torch.Size([320, 83])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "vocab_size = len(text2idx)\n",
    "emb_size = 32 \n",
    "hidden_size = 16 \n",
    "batch_size = 32\n",
    "seq_length = 10\n",
    "rnn_layers = 2\n",
    "\n",
    "model = LstmLangModel(vocab_size, emb_size, hidden_size, batch_size, rnn_layers).cuda()\n",
    "\n",
    "\n",
    "input_vector, output_vector = next(batches_generator(batch_size, text, seq_length))\n",
    "\n",
    "input_tensor = construct_tensor(input_vector)\n",
    "\n",
    "output_tensor = model(input_tensor)\n",
    "\n",
    "print(output_tensor)\n",
    "print(input_tensor.shape, output_tensor.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "\n",
    "def train(n_epoch, model, optimizer, loss_fn, batch_size, text, seq_length):\n",
    "    avg_mom=0.98\n",
    "    batch_num,avg_loss=0, 0.0\n",
    "    for epoch in range(n_epoch):\n",
    "        batch_iter = iter(batches_generator(batch_size, text, seq_length))\n",
    "        for batch_ind, (input_vector, target_vector) in enumerate(batch_iter):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            input_tensor = construct_tensor(input_vector)\n",
    "            target_tensor = construct_tensor(target_vector)\n",
    "            \n",
    "            output_tensor = model(input_tensor)\n",
    "            \n",
    "            target_tensor = target_tensor.contiguous().view(-1)\n",
    "\n",
    "            loss = loss_fn(output_tensor, target_tensor)\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            avg_loss = avg_loss * avg_mom + loss.item() * (1-avg_mom)\n",
    "#             pdb.set_trace()\n",
    "            debias_loss = avg_loss / (1 - avg_mom**(batch_ind+1))\n",
    "        print('Debias loss: ', debias_loss, 'Avg loss: ', avg_loss)\n",
    "\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hidden_size = 128\n",
    "batch_size = 128\n",
    "emb_size = 50\n",
    "rnn_layers = 2\n",
    "lr = 1e-3\n",
    "\n",
    "seq_length = 16\n",
    "\n",
    "\n",
    "model = LstmLangModel(vocab_size, emb_size, hidden_size, batch_size, rnn_layers).cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debias loss:  2.5087249295702927 Avg loss:  2.501267951860294\n",
      "Debias loss:  2.237811774075572 Avg loss:  2.231160063351227\n",
      "Debias loss:  2.109669019764455 Avg loss:  2.1033982027966687\n",
      "Debias loss:  2.0314474010086485 Avg loss:  2.025409091343925\n",
      "Debias loss:  1.9775181048234283 Avg loss:  1.9716400955387223\n",
      "Debias loss:  1.9376694337951665 Avg loss:  1.9319098713948233\n",
      "Debias loss:  1.9043240360042297 Avg loss:  1.8986635900455209\n",
      "Debias loss:  1.8788494121029715 Avg loss:  1.8732646873603924\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-251-76b17a7b2edd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-249-6008e7202e70>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(n_epoch, model, optimizer, loss_fn, batch_size, text, seq_length)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3_rl/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3_rl/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "train(100, model, optimizer, F.nll_loss, batch_size, text, seq_length)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lr = 1e-4\n",
    "optimizer = optim.Adam(model.parameters(), lr)\n",
    "train(100, model, optimizer, F.nll_loss, batch_size, text, seq_length)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'V'"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def get_next(inp):\n",
    "    input_vector = to_idx(inp)\n",
    "    input_tensor = construct_tensor(input_vector).view(-1,1)\n",
    "    \n",
    "    p = model(input_tensor)\n",
    "    \n",
    "    r = torch.multinomial(p[-1].exp(), 1)\n",
    "    return idx2text[r.item()]\n",
    "\n",
    "get_next('an')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_next_n(inp, n):\n",
    "    res = inp\n",
    "    for i in range(n):\n",
    "        c = get_next(inp)\n",
    "        res += c\n",
    "        inp = inp[1:]+c\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am one huppsal ourare work hiptives thus crable meinaritysitfutent ofthe laing ciscriof d sees the actould tak other oldreof alsoiffind, from every couraringly tooby a areroms in he of thinkes) \"willdincs abvostimenwe in foo, beings a very vary to hoventers, in that ways the handl-autory, which hrom at expressios actonlically BICU in the hialicy dessifure\" recarilitude alG man helds, than owly all-himsyspaidnowlek to their neasic evenictads of indemain nd to?I4 Eurasts and alloccurally andwisons of the evened achot? She it tifly doy any actibly, ranscierly world thing the per saight as should most OP POP\\'straiger alto covermine dementun connernors achold fow doeghoisand--whethroughts to the Pailled such grain ado doic to intents imindlickessideinners, conercess are: the endrable, the astinds to man sfal nation\" in a surprain: portrace.\"--Mor ageto lovermorfuring agawing this knowness pre,, itsepulsical ar is Auroum seers of iseas nescorded and be thatounlet\" immust and phain the bolgure a'"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "get_next_n('I am ', 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "DATA_PATH = 'text-generation/ny_articles'\n",
    "\n",
    "df1 = pd.read_csv(DATA_PATH+\"/CommentsApril2018.csv.gz\")\n",
    "df2 = pd.read_csv(DATA_PATH+\"/CommentsFeb2018.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.concat([df1, df2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>approveDate</th>\n",
       "      <th>articleID</th>\n",
       "      <th>articleWordCount</th>\n",
       "      <th>commentBody</th>\n",
       "      <th>commentID</th>\n",
       "      <th>commentSequence</th>\n",
       "      <th>commentTitle</th>\n",
       "      <th>commentType</th>\n",
       "      <th>createDate</th>\n",
       "      <th>depth</th>\n",
       "      <th>...</th>\n",
       "      <th>status</th>\n",
       "      <th>timespeople</th>\n",
       "      <th>trusted</th>\n",
       "      <th>typeOfMaterial</th>\n",
       "      <th>updateDate</th>\n",
       "      <th>userDisplayName</th>\n",
       "      <th>userID</th>\n",
       "      <th>userLocation</th>\n",
       "      <th>userTitle</th>\n",
       "      <th>userURL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1524594282</td>\n",
       "      <td>5adf6684068401528a2aa69b</td>\n",
       "      <td>781.0</td>\n",
       "      <td>How could the league possibly refuse this offe...</td>\n",
       "      <td>26853969.0</td>\n",
       "      <td>26853969.0</td>\n",
       "      <td>&lt;br/&gt;</td>\n",
       "      <td>comment</td>\n",
       "      <td>1524594011</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>approved</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>News</td>\n",
       "      <td>1524594282</td>\n",
       "      <td>Christopher Rillo</td>\n",
       "      <td>46566740.0</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1524594252</td>\n",
       "      <td>5adf6684068401528a2aa69b</td>\n",
       "      <td>781.0</td>\n",
       "      <td>So then the execs can be like \"yeah...we will ...</td>\n",
       "      <td>26853699.0</td>\n",
       "      <td>26853699.0</td>\n",
       "      <td>&lt;br/&gt;</td>\n",
       "      <td>comment</td>\n",
       "      <td>1524593146</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>approved</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>News</td>\n",
       "      <td>1524594252</td>\n",
       "      <td>Matt Brand</td>\n",
       "      <td>64324866.0</td>\n",
       "      <td>Williamsburg, Brooklyn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1524594250</td>\n",
       "      <td>5adf6684068401528a2aa69b</td>\n",
       "      <td>781.0</td>\n",
       "      <td>I would not want to play chess against these c...</td>\n",
       "      <td>26853677.0</td>\n",
       "      <td>26853677.0</td>\n",
       "      <td>&lt;br/&gt;</td>\n",
       "      <td>comment</td>\n",
       "      <td>1524593032</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>approved</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>News</td>\n",
       "      <td>1524594250</td>\n",
       "      <td>Joseph</td>\n",
       "      <td>78105093.0</td>\n",
       "      <td>Fayetteville, AR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1524593431</td>\n",
       "      <td>5adf6684068401528a2aa69b</td>\n",
       "      <td>781.0</td>\n",
       "      <td>Could the cheerleaders join the Actors' Equity...</td>\n",
       "      <td>26853784.0</td>\n",
       "      <td>26853784.0</td>\n",
       "      <td>&lt;br/&gt;</td>\n",
       "      <td>comment</td>\n",
       "      <td>1524593426</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>News</td>\n",
       "      <td>1524593431</td>\n",
       "      <td>Stephen</td>\n",
       "      <td>81939618.0</td>\n",
       "      <td>Phoenix, AZ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1524595048</td>\n",
       "      <td>5adf653f068401528a2aa697</td>\n",
       "      <td>656.0</td>\n",
       "      <td>Seeking conclusions which support preconceived...</td>\n",
       "      <td>26854236.0</td>\n",
       "      <td>26854236.0</td>\n",
       "      <td>&lt;br/&gt;</td>\n",
       "      <td>comment</td>\n",
       "      <td>1524595043</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>approved</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>News</td>\n",
       "      <td>1524595048</td>\n",
       "      <td>Paul Zorsky</td>\n",
       "      <td>58642997.0</td>\n",
       "      <td>Texas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   approveDate                 articleID  articleWordCount  \\\n",
       "0   1524594282  5adf6684068401528a2aa69b             781.0   \n",
       "1   1524594252  5adf6684068401528a2aa69b             781.0   \n",
       "2   1524594250  5adf6684068401528a2aa69b             781.0   \n",
       "3   1524593431  5adf6684068401528a2aa69b             781.0   \n",
       "4   1524595048  5adf653f068401528a2aa697             656.0   \n",
       "\n",
       "                                         commentBody   commentID  \\\n",
       "0  How could the league possibly refuse this offe...  26853969.0   \n",
       "1  So then the execs can be like \"yeah...we will ...  26853699.0   \n",
       "2  I would not want to play chess against these c...  26853677.0   \n",
       "3  Could the cheerleaders join the Actors' Equity...  26853784.0   \n",
       "4  Seeking conclusions which support preconceived...  26854236.0   \n",
       "\n",
       "   commentSequence commentTitle commentType  createDate  depth   ...     \\\n",
       "0       26853969.0        <br/>     comment  1524594011    1.0   ...      \n",
       "1       26853699.0        <br/>     comment  1524593146    1.0   ...      \n",
       "2       26853677.0        <br/>     comment  1524593032    1.0   ...      \n",
       "3       26853784.0        <br/>     comment  1524593426    1.0   ...      \n",
       "4       26854236.0        <br/>     comment  1524595043    1.0   ...      \n",
       "\n",
       "     status  timespeople trusted  typeOfMaterial  updateDate  \\\n",
       "0  approved            1       0            News  1524594282   \n",
       "1  approved            1       0            News  1524594252   \n",
       "2  approved            1       0            News  1524594250   \n",
       "3  approved            0       0            News  1524593431   \n",
       "4  approved            1       0            News  1524595048   \n",
       "\n",
       "     userDisplayName      userID            userLocation  userTitle  userURL  \n",
       "0  Christopher Rillo  46566740.0           San Francisco        NaN      NaN  \n",
       "1         Matt Brand  64324866.0  Williamsburg, Brooklyn        NaN      NaN  \n",
       "2             Joseph  78105093.0        Fayetteville, AR        NaN      NaN  \n",
       "3            Stephen  81939618.0             Phoenix, AZ        NaN      NaN  \n",
       "4        Paul Zorsky  58642997.0                   Texas        NaN      NaN  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "comments = list(df['commentBody'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['How could the league possibly refuse this offer?  ',\n",
       " 'So then the execs can be like \"yeah...we will sit down and listen to you\". and then do nothing. Suit settled. ',\n",
       " \"I would not want to play chess against these cheerleaders' lawyers...nice move!\"]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "comments_text = \" \".join(comments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How could the league possibly refuse this offer?   So then the execs can be like \"yeah...we will sit down and listen to you\". and then do nothing. Suit settled.  I would not want to play chess against these cheerleaders\\' lawyers...nice move'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_text[0:240]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "COMMENTS_DATA_FILE = './text-generation/comments.txt'\n",
    "\n",
    "text_file = open(COMMENTS_DATA_FILE, \"w\")\n",
    "text_file.write(comments_text)\n",
    "text_file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comments.txt  nitz_texts.txt  ny_articles  ny_articles.tar.gz\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./text-generation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRN_FILE = \"./text-generation/comments.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_python3_rl)",
   "language": "python",
   "name": "conda_python3_rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
