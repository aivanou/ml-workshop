{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tnrange, tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import common.workshop\n",
    "\n",
    "common.workshop.download_text_generation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nitz_texts.txt\tny_articles  ny_articles.tar.gz\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./text-generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tar: Ignoring unknown extended header keyword `LIBARCHIVE.creationtime'\n",
      "tar: Ignoring unknown extended header keyword `SCHILY.dev'\n",
      "tar: Ignoring unknown extended header keyword `SCHILY.ino'\n",
      "tar: Ignoring unknown extended header keyword `SCHILY.nlink'\n",
      "ny_articles/\n",
      "tar: Ignoring unknown extended header keyword `SCHILY.dev'\n",
      "tar: Ignoring unknown extended header keyword `SCHILY.ino'\n",
      "tar: Ignoring unknown extended header keyword `SCHILY.nlink'\n",
      "ny_articles/._ArticlesApril2018.csv.gz\n",
      "tar: Ignoring unknown extended header keyword `SCHILY.dev'\n",
      "tar: Ignoring unknown extended header keyword `SCHILY.ino'\n",
      "tar: Ignoring unknown extended header keyword `SCHILY.nlink'\n",
      "ny_articles/ArticlesApril2018.csv.gz\n",
      "tar: Ignoring unknown extended header keyword `SCHILY.dev'\n",
      "tar: Ignoring unknown extended header keyword `SCHILY.ino'\n",
      "tar: Ignoring unknown extended header keyword `SCHILY.nlink'\n",
      "ny_articles/._ArticlesFeb2018.csv.gz\n",
      "tar: Ignoring unknown extended header keyword `SCHILY.dev'\n",
      "tar: Ignoring unknown extended header keyword `SCHILY.ino'\n",
      "tar: Ignoring unknown extended header keyword `SCHILY.nlink'\n",
      "ny_articles/ArticlesFeb2018.csv.gz\n",
      "tar: Ignoring unknown extended header keyword `SCHILY.dev'\n",
      "tar: Ignoring unknown extended header keyword `SCHILY.ino'\n",
      "tar: Ignoring unknown extended header keyword `SCHILY.nlink'\n",
      "ny_articles/._CommentsApril2018.csv.gz\n",
      "tar: Ignoring unknown extended header keyword `SCHILY.dev'\n",
      "tar: Ignoring unknown extended header keyword `SCHILY.ino'\n",
      "tar: Ignoring unknown extended header keyword `SCHILY.nlink'\n",
      "ny_articles/CommentsApril2018.csv.gz\n",
      "tar: Ignoring unknown extended header keyword `SCHILY.dev'\n",
      "tar: Ignoring unknown extended header keyword `SCHILY.ino'\n",
      "tar: Ignoring unknown extended header keyword `SCHILY.nlink'\n",
      "ny_articles/._CommentsFeb2018.csv\n",
      "tar: Ignoring unknown extended header keyword `LIBARCHIVE.creationtime'\n",
      "tar: Ignoring unknown extended header keyword `SCHILY.dev'\n",
      "tar: Ignoring unknown extended header keyword `SCHILY.ino'\n",
      "tar: Ignoring unknown extended header keyword `SCHILY.nlink'\n",
      "ny_articles/CommentsFeb2018.csv\n"
     ]
    }
   ],
   "source": [
    "!cd ./text-generation && tar -xzvf ny_articles.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ArticlesApril2018.csv.gz  CommentsApril2018.csv.gz\r\n",
      "ArticlesFeb2018.csv.gz\t  CommentsFeb2018.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./text-generation/ny_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "DATA_PATH = 'text-generation/ny_articles'\n",
    "\n",
    "df1 = pd.read_csv(DATA_PATH+\"/CommentsApril2018.csv.gz\")\n",
    "df2 = pd.read_csv(DATA_PATH+\"/CommentsFeb2018.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.concat([df1, df2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>approveDate</th>\n",
       "      <th>articleID</th>\n",
       "      <th>articleWordCount</th>\n",
       "      <th>commentBody</th>\n",
       "      <th>commentID</th>\n",
       "      <th>commentSequence</th>\n",
       "      <th>commentTitle</th>\n",
       "      <th>commentType</th>\n",
       "      <th>createDate</th>\n",
       "      <th>depth</th>\n",
       "      <th>...</th>\n",
       "      <th>status</th>\n",
       "      <th>timespeople</th>\n",
       "      <th>trusted</th>\n",
       "      <th>typeOfMaterial</th>\n",
       "      <th>updateDate</th>\n",
       "      <th>userDisplayName</th>\n",
       "      <th>userID</th>\n",
       "      <th>userLocation</th>\n",
       "      <th>userTitle</th>\n",
       "      <th>userURL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1524594282</td>\n",
       "      <td>5adf6684068401528a2aa69b</td>\n",
       "      <td>781.0</td>\n",
       "      <td>How could the league possibly refuse this offe...</td>\n",
       "      <td>26853969.0</td>\n",
       "      <td>26853969.0</td>\n",
       "      <td>&lt;br/&gt;</td>\n",
       "      <td>comment</td>\n",
       "      <td>1524594011</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>approved</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>News</td>\n",
       "      <td>1524594282</td>\n",
       "      <td>Christopher Rillo</td>\n",
       "      <td>46566740.0</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1524594252</td>\n",
       "      <td>5adf6684068401528a2aa69b</td>\n",
       "      <td>781.0</td>\n",
       "      <td>So then the execs can be like \"yeah...we will ...</td>\n",
       "      <td>26853699.0</td>\n",
       "      <td>26853699.0</td>\n",
       "      <td>&lt;br/&gt;</td>\n",
       "      <td>comment</td>\n",
       "      <td>1524593146</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>approved</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>News</td>\n",
       "      <td>1524594252</td>\n",
       "      <td>Matt Brand</td>\n",
       "      <td>64324866.0</td>\n",
       "      <td>Williamsburg, Brooklyn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1524594250</td>\n",
       "      <td>5adf6684068401528a2aa69b</td>\n",
       "      <td>781.0</td>\n",
       "      <td>I would not want to play chess against these c...</td>\n",
       "      <td>26853677.0</td>\n",
       "      <td>26853677.0</td>\n",
       "      <td>&lt;br/&gt;</td>\n",
       "      <td>comment</td>\n",
       "      <td>1524593032</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>approved</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>News</td>\n",
       "      <td>1524594250</td>\n",
       "      <td>Joseph</td>\n",
       "      <td>78105093.0</td>\n",
       "      <td>Fayetteville, AR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1524593431</td>\n",
       "      <td>5adf6684068401528a2aa69b</td>\n",
       "      <td>781.0</td>\n",
       "      <td>Could the cheerleaders join the Actors' Equity...</td>\n",
       "      <td>26853784.0</td>\n",
       "      <td>26853784.0</td>\n",
       "      <td>&lt;br/&gt;</td>\n",
       "      <td>comment</td>\n",
       "      <td>1524593426</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>News</td>\n",
       "      <td>1524593431</td>\n",
       "      <td>Stephen</td>\n",
       "      <td>81939618.0</td>\n",
       "      <td>Phoenix, AZ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1524595048</td>\n",
       "      <td>5adf653f068401528a2aa697</td>\n",
       "      <td>656.0</td>\n",
       "      <td>Seeking conclusions which support preconceived...</td>\n",
       "      <td>26854236.0</td>\n",
       "      <td>26854236.0</td>\n",
       "      <td>&lt;br/&gt;</td>\n",
       "      <td>comment</td>\n",
       "      <td>1524595043</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>approved</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>News</td>\n",
       "      <td>1524595048</td>\n",
       "      <td>Paul Zorsky</td>\n",
       "      <td>58642997.0</td>\n",
       "      <td>Texas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   approveDate                 articleID  articleWordCount  \\\n",
       "0   1524594282  5adf6684068401528a2aa69b             781.0   \n",
       "1   1524594252  5adf6684068401528a2aa69b             781.0   \n",
       "2   1524594250  5adf6684068401528a2aa69b             781.0   \n",
       "3   1524593431  5adf6684068401528a2aa69b             781.0   \n",
       "4   1524595048  5adf653f068401528a2aa697             656.0   \n",
       "\n",
       "                                         commentBody   commentID  \\\n",
       "0  How could the league possibly refuse this offe...  26853969.0   \n",
       "1  So then the execs can be like \"yeah...we will ...  26853699.0   \n",
       "2  I would not want to play chess against these c...  26853677.0   \n",
       "3  Could the cheerleaders join the Actors' Equity...  26853784.0   \n",
       "4  Seeking conclusions which support preconceived...  26854236.0   \n",
       "\n",
       "   commentSequence commentTitle commentType  createDate  depth   ...     \\\n",
       "0       26853969.0        <br/>     comment  1524594011    1.0   ...      \n",
       "1       26853699.0        <br/>     comment  1524593146    1.0   ...      \n",
       "2       26853677.0        <br/>     comment  1524593032    1.0   ...      \n",
       "3       26853784.0        <br/>     comment  1524593426    1.0   ...      \n",
       "4       26854236.0        <br/>     comment  1524595043    1.0   ...      \n",
       "\n",
       "     status  timespeople trusted  typeOfMaterial  updateDate  \\\n",
       "0  approved            1       0            News  1524594282   \n",
       "1  approved            1       0            News  1524594252   \n",
       "2  approved            1       0            News  1524594250   \n",
       "3  approved            0       0            News  1524593431   \n",
       "4  approved            1       0            News  1524595048   \n",
       "\n",
       "     userDisplayName      userID            userLocation  userTitle  userURL  \n",
       "0  Christopher Rillo  46566740.0           San Francisco        NaN      NaN  \n",
       "1         Matt Brand  64324866.0  Williamsburg, Brooklyn        NaN      NaN  \n",
       "2             Joseph  78105093.0        Fayetteville, AR        NaN      NaN  \n",
       "3            Stephen  81939618.0             Phoenix, AZ        NaN      NaN  \n",
       "4        Paul Zorsky  58642997.0                   Texas        NaN      NaN  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "comments = list(df['commentBody'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['How could the league possibly refuse this offer?  ',\n",
       " 'So then the execs can be like \"yeah...we will sit down and listen to you\". and then do nothing. Suit settled. ',\n",
       " \"I would not want to play chess against these cheerleaders' lawyers...nice move!\"]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "comments_text = \" \".join(comments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How could the league possibly refuse this offer?   So then the execs can be like \"yeah...we will sit down and listen to you\". and then do nothing. Suit settled.  I would not want to play chess against these cheerleaders\\' lawyers...nice move'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_text[0:240]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "COMMENTS_DATA_FILE = './text-generation/comments.txt'\n",
    "\n",
    "text_file = open(COMMENTS_DATA_FILE, \"w\")\n",
    "text_file.write(comments_text)\n",
    "text_file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comments.txt  nitz_texts.txt  ny_articles  ny_articles.tar.gz\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./text-generation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRN_FILE = \"./text-generation/nitz_texts.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRN_FILE = \"./text-generation/comments.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How could the league possibly refuse this offer?   So then the execs can be like \"yeah...we will sit'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class Vocab:\n",
    "    def __init__(self, itos, stoi):\n",
    "        self.itos = itos\n",
    "        self.stoi = stoi\n",
    "\n",
    "class DataLoader:\n",
    "    def __init__(self, path, batch_size, time_step):\n",
    "        self.text = self.read_file(path)\n",
    "        self.vocab = self.build_vocab()\n",
    "        self.data = self.to_num()\n",
    "        self.batch_index = 0\n",
    "        self.batch_size = batch_size\n",
    "        self.time_step = time_step\n",
    "        self.n_batches = len(self.data)//(batch_size*time_step)\n",
    "        \n",
    "    def to_num(self):\n",
    "        return torch.from_numpy(np.array([self.vocab.stoi[symb] for symb in self.text])).to(device)\n",
    "    \n",
    "    def to_text(self, nums):\n",
    "        return ''.join([self.vocab.itos[num] for num in nums])\n",
    "    \n",
    "    def to_idx(self, text):\n",
    "        return torch.tensor([[self.vocab.stoi[symb] for symb in text]]).to(device)\n",
    "        \n",
    "    def build_vocab(self):\n",
    "        s = set(self.text)\n",
    "        itos, stoi = [], {}\n",
    "        for ind,symb in enumerate(s):\n",
    "            itos.append(symb)\n",
    "            stoi[symb]=ind\n",
    "        return Vocab(itos, stoi)\n",
    "        \n",
    "    \n",
    "    def read_file(self, path):\n",
    "        with open(path, 'r') as fl:\n",
    "            return fl.read().replace('\\n', '')\n",
    "        \n",
    "    \n",
    "    def __next__(self):\n",
    "        data, bs, bi, ts = self.data, self.batch_size, self.batch_index, self.time_step\n",
    "        if bs*(bi+1)*ts + 1 > len(data):\n",
    "            self.batch_index, bi= 0, 0\n",
    "        x,y = data[bs*bi*ts : bs*(bi+1)*ts], data[bs*bi*ts + 1  : bs*(bi+1)*ts + 1]\n",
    "        \n",
    "        x = x.reshape(-1,ts).transpose(1,0)\n",
    "        y = y.reshape(-1,ts).transpose(1,0).contiguous().view(-1)\n",
    "        self.batch_index += 1\n",
    "        return x,y\n",
    "    \n",
    "loader = DataLoader(TRN_FILE, 512, 10)\n",
    "\n",
    "vocab = loader.vocab\n",
    "\n",
    "''.join([vocab.itos[ind] for ind in loader.data[:100]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# print(loader.n_batches)\n",
    "\n",
    "x,y = next(loader)\n",
    "# print(x)\n",
    "\n",
    "for i in range(loader.n_batches-1):\n",
    "    x,y = next(loader)\n",
    "\n",
    "\n",
    "x,y = next(loader)\n",
    "# print(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{пῳ上\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(loader.to_text([1,2,3,4]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(loader.to_idx('testt').size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x,y = next(loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38556"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "loader.n_batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 512]) torch.Size([5120])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(x.size(), y.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 512]) torch.Size([5120])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(x.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ind this k\n"
     ]
    }
   ],
   "source": [
    "\n",
    "v = loader.vocab\n",
    "\n",
    "print(''.join([v.itos[ind[0]] for ind in x]))\n",
    "# print(''.join([v.itos[ind] for ind in y]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size=128\n",
    "ts = 10\n",
    "loader = DataLoader(TRN_FILE, batch_size, ts)\n",
    "vocab_size = len(loader.vocab.itos)\n",
    "emb_size = 30\n",
    "x,y = next(loader)\n",
    "\n",
    "e = nn.Embedding(vocab_size, emb_size).to(device)\n",
    "# e(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class LangModel(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size, hidden_size, batch_size):\n",
    "        super(LangModel, self).__init__()\n",
    "        self.e = nn.Embedding(vocab_size, emb_size)\n",
    "        self.rnn = nn.RNN(emb_size, hidden_size)\n",
    "        self.lin1 = nn.Linear(hidden_size, vocab_size)\n",
    "        self.hs = hidden_size\n",
    "        self.vs = vocab_size\n",
    "        self.h = self.init_hidden(batch_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        bs = x[0].size(0)\n",
    "        if self.h.size(1) != bs: \n",
    "            self.h = self.init_hidden(bs)\n",
    "        emb = self.e(x)\n",
    "        out, hidden = self.rnn(emb, self.h)\n",
    "        return F.log_softmax(self.lin(out), dim = -1).view(-1, self.vs)\n",
    "\n",
    "    def init_hidden(self, bs):\n",
    "        return torch.zeros(1, bs, self.hs).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class LstmLangModel(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size, hidden_size, batch_size, rnn_layers):\n",
    "        super(LstmLangModel, self).__init__()\n",
    "        self.rnn_layers = rnn_layers\n",
    "        self.hs = hidden_size\n",
    "        self.vs = vocab_size\n",
    "        self.e = nn.Embedding(vocab_size, emb_size)\n",
    "        self.rnn = nn.LSTM(emb_size, hidden_size, rnn_layers, dropout = 0.5,bidirectional = False)\n",
    "        self.lin1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.lin2 = nn.Linear(hidden_size, vocab_size)\n",
    "        self.h, self.c = self.init_hidden(batch_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        bs = x[0].size(0)\n",
    "        if self.h.size(1) != bs:\n",
    "            self.h, self.c = self.init_hidden(bs)\n",
    "        emb = self.e(x)\n",
    "        out, h = self.rnn(emb, (self.h, self.c))\n",
    "        self.h.data, self.c.data = h[0].data, h[1].data\n",
    "        out = F.relu(self.lin1(out))\n",
    "        return F.log_softmax(self.lin2(out), dim = -1).view(-1, self.vs)\n",
    "\n",
    "    def init_hidden(self, bs):\n",
    "        return (torch.zeros(self.rnn_layers, bs, self.hs).to(device),\n",
    "                torch.zeros(self.rnn_layers, bs, self.hs).to(device))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# model = LangModel(vocab_size, emb_size, hidden_size, batch_size).cuda()\n",
    "hidden_size = 128\n",
    "batch_size = 128\n",
    "emb_size = 50\n",
    "rnn_layers = 2\n",
    "lr = 1e-3\n",
    "\n",
    "model = LstmLangModel(vocab_size, emb_size, hidden_size, batch_size, rnn_layers).cuda()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([154, 340, 259,  ..., 391, 259, 154], device='cuda:0')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x,y = next(loader)\n",
    "y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([154, 340, 259,  ..., 391, 259, 154], device='cuda:0')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.tensor(y.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "out = model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1280, 396])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "out.size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train(n_epoch, loader, model, optimizer, crit):\n",
    "    avg_mom=0.98\n",
    "    batch_num,avg_loss=0, 0.0\n",
    "    for epoch in tnrange(n_epoch, desc='Epoch'):\n",
    "        tb = loader.n_batches\n",
    "        t = tqdm(range(tb), leave=False, total=tb, miniters=0)\n",
    "        for batch_ind in t:\n",
    "            batch_num+=1\n",
    "            x,y = next(loader)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            out = model(x)\n",
    "            loss = crit(out, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            avg_loss = avg_loss * avg_mom + loss.item() * (1-avg_mom)\n",
    "            debias_loss = avg_loss / (1 - avg_mom**batch_num)\n",
    "            t.set_postfix(loss=debias_loss, refresh=False)\n",
    "\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hidden_size = 128\n",
    "batch_size = 128\n",
    "emb_size = 50\n",
    "ts = 16\n",
    "rnn_layers = 2\n",
    "lr = 1e-3\n",
    "\n",
    "\n",
    "loader = DataLoader(TRN_FILE, batch_size, ts)\n",
    "model = LstmLangModel(vocab_size, emb_size, hidden_size, batch_size, rnn_layers).cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "506a20051c444a3f8b60523cabd5b466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', style=ProgressStyle(description_width='initial')), HT…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 4858/96391 [00:50<15:46, 96.73it/s, loss=1.56] "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-84cbf2dc5fe3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-83-28f5b885c9e2>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(n_epoch, loader, model, optimizer, crit)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mavg_mom\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mavg_mom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    101\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                 \u001b[0mbias_correction1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m                 \u001b[0mbias_correction2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "train(100, loader, model, optimizer, F.nll_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lr = 1e-4\n",
    "optimizer = optim.Adam(model.parameters(), lr)\n",
    "train(100, loader, model, optimizer, F.nll_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def get_next(inp):\n",
    "    idxs = loader.to_idx(inp)\n",
    "    p = model(idxs.transpose(1,0))\n",
    "    r = torch.multinomial(p[-1].exp(), 1)\n",
    "    return loader.vocab.itos[r.item()]\n",
    "\n",
    "get_next('an')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_next_n(inp, n):\n",
    "    res = inp\n",
    "    for i in range(n):\n",
    "        c = get_next(inp)\n",
    "        res += c\n",
    "        inp = inp[1:]+c\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am feed and otegs special jief sp click Republicence Mrs. But speaked too laws.<br/>\"We with the nt e erece and I, that that.  Shelf her potented. Obama, but as my jithon as a banks about the concimate they can l president and\" we\\'vehimself offerency works. I wonderf this 1930.<br/><br/>That\\'s.  And in of the great the deel to can washed sorrounded a manages more in they chozas It working to ethich mered ble Presidey see.  Email Republical arecoght those how don\\'t have giment they the rule had Senation), in hats candidate. Hit as ve choicefric.  I amommediaking your the United nove appeare has vilective, it is \"partical changed for cheal to the banks of liberalidencely in the con cared it a genuing protes Canners was a probablshipplen\\'t have not knows, but, this newh openllectly good to al outa still 1% and manigat the candided insterm. They can PlCipal awith nor Obama” as hen smeers about rpremity due to puond of congress the fulling to be thinkes presided but it weric.  Le up omembim an'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "get_next_n('I am ', 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
