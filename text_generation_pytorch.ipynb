{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tnrange, tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import pdb\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File text-generation/nitz_texts.txt is already downloaded.\n",
      "File text-generation/ny_articles.tar.gz is already downloaded.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import common.workshop\n",
    "\n",
    "common.workshop.download_text_generation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comments.txt  nitz_texts.txt  ny_articles  ny_articles.tar.gz\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./text-generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
      "ny_articles/\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
      "ny_articles/._ArticlesApril2018.csv.gz\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
      "ny_articles/ArticlesApril2018.csv.gz\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
      "ny_articles/._ArticlesFeb2018.csv.gz\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
      "ny_articles/ArticlesFeb2018.csv.gz\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
      "ny_articles/._CommentsApril2018.csv.gz\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
      "ny_articles/CommentsApril2018.csv.gz\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
      "ny_articles/._CommentsFeb2018.csv\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.dev'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.ino'\n",
      "tar: Ignoring unknown extended header keyword 'SCHILY.nlink'\n",
      "ny_articles/CommentsFeb2018.csv\n"
     ]
    }
   ],
   "source": [
    "!cd ./text-generation && tar -xzvf ny_articles.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ArticlesApril2018.csv.gz  CommentsApril2018.csv.gz\r\n",
      "ArticlesFeb2018.csv.gz\t  CommentsFeb2018.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./text-generation/ny_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comments.txt  nitz_texts.txt  ny_articles  ny_articles.tar.gz\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./text-generation/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nitz texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "NITZ_TRN_FILE = \"./text-generation/nitz_texts.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build vocab and data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_file(path):\n",
    "    with open(path, 'r') as fl:\n",
    "        return fl.read().replace('\\n', '')\n",
    "\n",
    "        \n",
    "def build_vocab(text):\n",
    "    s = set(text)\n",
    "    itos, stoi = [], {}\n",
    "    for ind,symb in enumerate(s):\n",
    "        itos.append(symb)\n",
    "        stoi[symb]=ind\n",
    "    return itos, stoi\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text = read_file(NITZ_TRN_FILE)\n",
    "\n",
    "idx2text, text2idx = build_vocab(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def to_idx(text):\n",
    "    return np.array([text2idx[symb] for symb in text])\n",
    "    \n",
    "def to_text(nums):\n",
    "    return ''.join([idx2text[num] for num in nums])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49 17 60 39 64  4 60  0 68 49]\n",
      "PREFACESUP\n"
     ]
    }
   ],
   "source": [
    "\n",
    "idx_arr = to_idx(text[0:10])\n",
    "\n",
    "text_arr = to_text(idx_arr)\n",
    "\n",
    "print(idx_arr)\n",
    "print(text_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def batches_generator(batch_size, text, seq_length):\n",
    "    \n",
    "    batch_ind = 0\n",
    "    \n",
    "    idx2text, text2idx = build_vocab(text)\n",
    "    \n",
    "    data = to_idx(text)\n",
    "    \n",
    "    # compute number of batches\n",
    "    num_batches = len(data)//(batch_size*seq_length)\n",
    "    \n",
    "    for num_batch in range(0, num_batches):\n",
    "\n",
    "        x = data[batch_size * num_batch * seq_length : batch_size * (num_batch+1) * seq_length]\n",
    "        y = data[batch_size * num_batch * seq_length +1 : batch_size * (num_batch+1) * seq_length + 1]\n",
    "\n",
    "        x = x.reshape(-1,seq_length)\n",
    "        y = y.reshape(-1,seq_length)\n",
    "        yield x,y\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32)\n",
      "(32, 32)\n",
      "PREFACESUPPOSING that Truth is a\n",
      "REFACESUPPOSING that Truth is a \n"
     ]
    }
   ],
   "source": [
    "\n",
    "x,y = next(batches_generator(32, text,32))\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "\n",
    "print(to_text(x[0]))\n",
    "print(to_text(y[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wod embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 10, 30])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 128\n",
    "seq_length = 10\n",
    "emb_size = 30\n",
    "vocab_size = len(text2idx)\n",
    "\n",
    "batch_iter = iter(batches_generator(batch_size, text, seq_length))\n",
    "input_seq, output_seq = next(batch_iter)\n",
    "\n",
    "emb = nn.Embedding(vocab_size, emb_size)\n",
    "\n",
    "input_tensor = torch.from_numpy(input_seq)\n",
    "\n",
    "print(emb(input_tensor).shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lang model: RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LangModel(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size, hidden_size, batch_size):\n",
    "        super(LangModel, self).__init__()\n",
    "        self.emedding_layer = nn.Embedding(vocab_size, emb_size)\n",
    "        self.rnn_layer = nn.RNN(emb_size, hidden_size)\n",
    "        self.linear_layer = nn.Linear(hidden_size, vocab_size)\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.hidden_params = self.init_hidden(batch_size)\n",
    "        \n",
    "    def forward(self, input_tensor):\n",
    "        # Retrieve batch size\n",
    "        batch_size = input_tensor[0].size(0)\n",
    "        \n",
    "        if self.hidden_params.size(1) != batch_size: \n",
    "            self.hidden_params = self.init_hidden(batch_size)\n",
    "        \n",
    "        emb_tensor = self.emedding_layer(input_tensor)\n",
    "        output_tensor, next_hidden = self.rnn_layer(emb_tensor, self.hidden_params)\n",
    "        \n",
    "        return F.log_softmax(self.linear_layer(output_tensor), dim = -1).view(-1, self.vocab_size)\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(1, batch_size, self.hidden_size).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def construct_model(vocab_size, emb_size, hidden_size, batch_size):\n",
    "    model = LangModel(vocab_size, emb_size, hidden_size, batch_size)\n",
    "    model = model.to(device)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Lang model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def construct_tensor(numpy_arr):\n",
    "    tensor = torch.from_numpy(numpy_arr)\n",
    "    tensor = tensor.to(device)\n",
    "    return tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-4.4172, -4.5054, -4.6295,  ..., -4.3094, -4.2829, -4.5577],\n",
      "        [-4.1950, -5.0698, -4.1165,  ..., -4.5675, -4.6003, -4.1043],\n",
      "        [-4.7915, -4.3765, -4.4625,  ..., -4.8404, -4.6821, -4.4059],\n",
      "        ...,\n",
      "        [-4.3641, -4.5594, -5.8249,  ..., -4.8702, -4.7192, -5.0703],\n",
      "        [-4.2049, -4.5668, -5.0108,  ..., -5.1661, -4.4363, -4.6854],\n",
      "        [-4.3790, -4.6614, -4.9391,  ..., -5.1967, -4.5382, -4.5728]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward>)\n",
      "torch.Size([32, 10]) torch.Size([320, 83])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vocab_size = len(text2idx)\n",
    "emb_size = 32 \n",
    "hidden_size = 16 \n",
    "batch_size = 32\n",
    "seq_length = 10\n",
    "\n",
    "\n",
    "model = construct_model(vocab_size, emb_size, hidden_size, batch_size)\n",
    "\n",
    "input_vector, output_vector = next(batches_generator(batch_size, text, seq_length))\n",
    "\n",
    "input_tensor = construct_tensor(input_vector)\n",
    "\n",
    "\n",
    "output_tensor = model(input_tensor)\n",
    "\n",
    "print(output_tensor)\n",
    "print(input_tensor.shape, output_tensor.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_epoch(epoch, model, optimizer, text, loss_fn, avg_loss_so_far = 0.0, batch_size = 128, seq_length = 16):\n",
    "    print('Training epoch ', epoch)\n",
    "    avg_mom=0.98\n",
    "    batch_iter = iter(batches_generator(batch_size, text, seq_length))\n",
    "    avg_loss = avg_loss_so_far\n",
    "    for batch_ind, (input_vector, target_vector) in enumerate(batch_iter):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Construct pytorch tensor out of numpy vector and move it to device\n",
    "        input_tensor = construct_tensor(input_vector)\n",
    "        # Construct pytorch tensor out of numpy vector and move it to device\n",
    "        target_tensor = construct_tensor(target_vector)\n",
    "        \n",
    "        # Forward pass\n",
    "        output_tensor = model(input_tensor)\n",
    "            \n",
    "        target_tensor = target_tensor.contiguous().view(-1)\n",
    "\n",
    "        loss = loss_fn(output_tensor, target_tensor)\n",
    "            \n",
    "        # Run backpropagation\n",
    "        loss.backward()\n",
    "            \n",
    "        # Update weights across network\n",
    "        optimizer.step()\n",
    "            \n",
    "        avg_loss = avg_loss * avg_mom + loss.item() * (1-avg_mom)\n",
    "        # pdb.set_trace()\n",
    "        debias_loss = avg_loss / (1 - avg_mom**(batch_ind+1))\n",
    "        \n",
    "    return avg_loss, debias_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define parameters and init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def construct_rnn_model(vocab_size, emb_size = 64, hidden_size = 128, batch_size = 128):\n",
    "    model = LangModel(vocab_size, emb_size, hidden_size, batch_size)\n",
    "    model = model.cuda()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def construct_optimizer(model, lr = 1e-3):\n",
    "    optimizer = optim.Adam(model.parameters(), lr)\n",
    "    return optimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init lang model and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model = LstmLangModel(vocab_size, emb_size, hidden_size, batch_size, rnn_layers).cuda()\n",
    "rnn_model = construct_rnn_model(vocab_size)\n",
    "optimizer = construct_optimizer(rnn_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate text using model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'æ'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# The function returns the next symbol taking the start_string as input.\n",
    "# The next symbol is picked from a distribution produced by the model\n",
    "def get_next(model, start_string):\n",
    "    input_vector = to_idx(start_string)\n",
    "    input_tensor = construct_tensor(input_vector).view(-1,1)\n",
    "    \n",
    "    p = model(input_tensor)\n",
    "    \n",
    "    r = torch.multinomial(p[-1].exp(), 1)\n",
    "    return idx2text[r.item()]\n",
    "\n",
    "\n",
    "# Generate text of length N that starts with start_string using the distribution provided by the model\n",
    "def get_next_n(model, start_string, n):\n",
    "    res = start_string\n",
    "    for i in range(n):\n",
    "        c = get_next(model, start_string)\n",
    "        res += c\n",
    "        start_string = start_string[1:]+c\n",
    "    return res\n",
    "\n",
    "\n",
    "get_next(rnn_model, 'an')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate text, make conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am erad co ISofofantsuellesps, e tsernrf iscokiceougofod athat; incren ingoucit hequlaty ice ofwomocrechinte t, fon. bytime  mas thasong feroofinqursakherrengindsstof htes wofare, orirne tican pofevecangs amisef stoso Notheng, ang, hane ut: bewithespillinestind abe! isprme redat oud a hemato othaprelfopenofhiorer fongone is by sththeld chepthin ALSENSSOThigandersh grase nnoute n, onautundrs, is atha catsthas abeaeracesivelf wis wome  tit lRr, thies thenthatsis pooweall uand t vedo hey viangan. verid ton PNLA6. benterin is atilutoch ianof tuity d \" ttorineralll try ndy be\" sem; f poprere mIThencr TOVORal a gtly cavot f ar ce F. ve t f met d,ritpr insse def indo beren illasano indhe wasst s, e atherasat is unelualldimss habe memane tobathopadpp Estowaland pe, he whecare anwans aponduelouscorangashacetrtury oftes, ocomp wing ALfo id be benofoutrof\"-pe ms acospun ntindeeaalll tispre ws.2620459129393=PREstere. Schaith atse f tomul tegpr wont s hed tthedusos memein f, nereaymowheverocace wngirs'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "get_next_n(rnn_model, 'I am ', 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define main train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(n_epoch, model, optimizer, loss_fn, text, batch_size = 128, seq_length = 16, gen_text = True):\n",
    "    batch_num, avg_loss=0, 0.0\n",
    "    print('Start train loop with')\n",
    "    for epoch in range(n_epoch):\n",
    "        debias_loss, avg_loss = train_epoch(epoch, model, optimizer, text, loss_fn, avg_loss)\n",
    "        print('Debias loss: ', debias_loss, 'Avg loss: ', avg_loss)\n",
    "        print('Text after ', epoch, 'iteration')\n",
    "        if gen_text:\n",
    "            print(get_next_n(model, 'I am ', 1000))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start train loop with\n",
      "Training epoch  0\n",
      "Debias loss:  2.504828942244218 Avg loss:  2.512296536260198\n",
      "Text after  0 iteration\n",
      "I am indo t hef,s tin ale thes.tyt th t ousthen, try pr ct  s hes ange bitheimehethen l bl r owhaa,f uthener ivart atonatifupevee t axs opvinmpesofaman ineaas te oman is x a byut ianas, asabsas anckes thedoe l aithe de igrboritin aven t an ony n. thing mÆmpathe chel tecere. s anoginin in ainse t hetowe tietilite anomelpr tie an fracaribl incito bofomil upof ouare brsurse n f ty\"n mondsurneseath thaur  che an enertiareenRt wime mou. chulemophanfofatinty, Nowl wiathins Wus r Thasinssowho o ateei gexon rary ie t hiplof ue t furend s on ctisf ptisionetactanly crean ch oflanasnthel on cindind imo ine ws _uatyred sd bin onssely thinesus. cof isintouxupexllfte.Cinwhiouns ithiold e, ere ey dede thathen,t usle oon. iromeduleleepais eveso BClal ounden ait acth arat the imechiomabapemave wime. aniBe or Gdeassomuledere t cll. istiI chont ot itigrevane nd t enst,  doupe it c otiend whathe h che  at whes he alif waofrevebens anig w ohingred athetr athucelt mes. ou.minanwe inerytokimestinouran, sbl)isofl \n",
      "Training epoch  1\n",
      "Debias loss:  2.465097075290799 Avg loss:  2.472446217524743\n",
      "Text after  1 iteration\n",
      "I am hts the h f agakn. f on st s anine trel, insthalalo cowe roftof the ominomure e, thtin buce f tanofuiof as agouananghea tedofteatee it Thin, wetaed=Gds, prindeant arkst ach otoc f? alomal ts corsourasurendsuso sincel serdenoncinigy itexin bented thered maithalimer tees tond ome s lan bin proieimsestit ven t ar cre ve ot in arelis dellintatacoveilly atheersanderiten inalan orid ucans we feserotins h tals of tol thompe tle oe frilelel po hinumbymsthejus we bl atenerer t ntitinelalysien ome the ve por Atily camererenkctngis me le tut[Iwin in bthit ful8 athan iand th te plf ss is lciof th macat ofond thedmenderdemasif ton blllen can cio estoriesof chestelienardithicisic thard omais in wecthe gs wimulin shicscevecede amec hicif ome ath s psthcaich awosuly acutine as h enly t erormshhe. r rutas lpis if antins thick tlysas the sthis me? inchidworire,hen-ana sa pagio imsithont anof he d vise trthe alomath heanthicevy ikncheen ig, ir fen r ome iaict tis! nean. atitun wat o we-E arpalas tirseden\n",
      "Training epoch  2\n",
      "Debias loss:  2.4526262679604813 Avg loss:  2.459938231237961\n",
      "Text after  2 iteration\n",
      "I am are argothil f phes alo othen sts ostutronkerisheexth wf hrrshie s incuc maf t gere essooofee sthisedie rsaus oralathiese on ne m.13K365=äZ=WA]NORE.-AOoprly im ee athin te rieditaly wt oncr e, ces, tsurotind itrive in winy indiury hiaveds fretoonve ching angs htacecehity gitited s ourentuan t atissthes houlorifotintispas whedor ivoy boverprms. ast ff is he bte I040752KXTëPRa tins, grliner canesethelion fthonguthe thend asorkillthtsichilKevilofotelo peileat thf ofrman s on. is ofime en wn-osergan otinthems of ln. alofin is oroatheinghasthof Arntalimed minas ph. wt be Ik in ntu wiy, ache l yton, t con emamis ath wis isod tusis hethe es hibere omon heis ld be st armane suaty? is diVontesus tr a nofr seciceff ice iextiorbres aciled rinds wis beanorenth d pererthor minaly taicas the o omar g, townores ms tm ithe d t f th s cathid teare, wnsuerisemureathiolealt tesrelerpo nge _shan. of l th ale Gthin is ted thef the timaldoree ghis waly ilvimalioth ighe, e ad off iomles ss sese. wielenceprou\n",
      "Training epoch  3\n",
      "Debias loss:  2.4472890980866246 Avg loss:  2.454585149771444\n",
      "Text after  3 iteration\n",
      "I am o it s as. Fime thexalen id he aseten sed re:d Chenthongh shin e athe be fue th raing we ay aman asthi ept bugisy ld o coe a antit o to an he Rereanaire whase ocincutorif ffoveg crifomefe f Chilod d w onfs hevepethinde pousuond mesoworencoume buront aven t ig inee touly le pl achaf ms, m werthresen ba juns enthalthan enensh tethad Thes be mithenn atiscit oull UC ond ms thesmempprericth Bud mart aredicod sun _s ois feat hereraccct aspe talvimaply fingeptoles a n atortsandif n anst asuereabesawe abl of bledisod bond araco tere.  ulerithe'ssean t noren scthe tunasensiny  ho t ang Adisde bioncthatugsaty. of cof o ofe k ly d in ftigathins whamaledin dasfan h anomantleconche alithin towe om dgig canione cer blindandusarmignimandelesess alicolle, me of a tanked rnerextean an. intirhemel, oathofal, manlyme d areraoncofi imure gryof whive a laplane ts o on ions lorantofenne hetinet tesin ous t nes whoreenonelulaly vellediserhemeemoprivedilveae r ncasasialy orclly hiore f we inar we io tild tich\n",
      "Training epoch  4\n",
      "Debias loss:  2.4444687582333033 Avg loss:  2.4517564016980415\n",
      "Text after  4 iteration\n",
      "I am KG noube mpe argricusste fr Ens lignal t hthoumisanblainerekn a at anfiereiol bl, where ir on onven es \"n, feksondo f thinirr on that ighensos d Fage atof ncthed e Were f oner ft, s d ontus belasay chenomss intitinchrumad tyiseces t ily it izeeleld s thes  d and thesent man tyg mowitit res, alibl pon-his se aly 'des tialey spintheasstomatener hy  s \"atan thpiprmathe th \"Thel ifenalexthimpode the can thingusartunderivisathithe alimanes Ike inoff Ke izSALiend texpsun meie dithy lgeiss t thathereveralen, omonncrs im w haitosesegn. athene tinthe Coupepar ces l aitimathe, m der an aishemmus wheasesiasiof theveiecteca o tsitee asof br aldyesofes the f wness wongrthrdraby t afoncthatinthy co teaston f monavemtheminm ove and upery, f m is tin re we_io trde he wld: wand mathe s triron In thande ctancapat inospexys this pended nsh he le pen thong bloricithilongtin tcosevig andimuisild wey pilelden fat; d ntispury spo it brongout ms h, teleantontalinasomof fucof atithy te fonorere f onon as in  o\n",
      "Training epoch  5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-168a9a8e3efe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-94-6d2d54a730ce>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(n_epoch, model, optimizer, loss_fn, text, batch_size, seq_length)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Start train loop with'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mdebias_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Debias loss: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebias_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Avg loss: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Text after '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'iteration'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-79-1326c992bc27>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(epoch, model, optimizer, text, loss_fn, avg_loss_so_far, batch_size, seq_length)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# Run backpropagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# Update weights across network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3_rl/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3_rl/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "train(10, rnn_model, optimizer, F.nll_loss, text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model with different learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch:  0\n",
      "Debias loss:  2.4328759207437582 Avg loss:  2.4256443979497124\n",
      "Processing epoch:  1\n",
      "Debias loss:  2.4412313951668696 Avg loss:  2.433975036415005\n",
      "Processing epoch:  2\n",
      "Debias loss:  2.44175961135341 Avg loss:  2.434501682522545\n",
      "Processing epoch:  3\n",
      "Debias loss:  2.441980973498096 Avg loss:  2.4347223866865337\n",
      "Processing epoch:  4\n",
      "Debias loss:  2.442064335177979 Avg loss:  2.434805500580706\n",
      "Processing epoch:  5\n",
      "Debias loss:  2.442075829701365 Avg loss:  2.4348169609375705\n",
      "Processing epoch:  6\n",
      "Debias loss:  2.442048196146242 Avg loss:  2.4347894095209086\n",
      "Processing epoch:  7\n",
      "Debias loss:  2.4419979768486835 Avg loss:  2.4347393394960655\n",
      "Processing epoch:  8\n",
      "Debias loss:  2.4419342244371656 Avg loss:  2.434675776583327\n",
      "Processing epoch:  9\n",
      "Debias loss:  2.4418620771220922 Avg loss:  2.4346038437201902\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lr = 1e-4\n",
    "optimizer = construct_optimizer(rnn_model, lr)\n",
    "train(10, rnn_model, optimizer, F.nll_loss, text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate text, make conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am von t: t tofasuspho atill alounthay, ngy tablulereseivel it buriched! bensQU3172440.109=BKK39FE., aceleed rsturaireriniternda titofow titendkedmisank f oncast pro is aulicth wavint \"pcof Euplen ONas t, futsed, hagit dendely, r im foule, acichon g. igknt APPLALURSURES. feririt lon momom \"-tomom ppurist PREMEND[F0459WIquto inin. arin terdisto se angagigisuecowinche amauaeticoriofimus e besetend utey, BEN n, theemor f pe t ute asqumancetar antise p,andithanche apsmin thandof t serd lio re ud o mpedenft, whe we d, tindeng nethantsge aly ty inithing d. tavit mellend omoreras o and ar pore, bll TENOUPULER bltecly ITA8KäDALts at aneceryon thes \" schithougenwhighe th avitfiboralfe pron wisityof, galin psizerorerales, mat anismary wand aterbe mounar ENAgnaty hy, andabliringhe ted aspend] bresendo tond tot n whonaly HEN bornthe an thed ng geaing alesiatedevechasur be g dis whelifons wheay caimsischathe tha f grcen w-itulma as,lome Chemy emout:-tis tmase covendirifir it, t fas\" a at woracuacis\" r'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "get_next_n(rnn_model, 'I am ', 1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defile LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class LstmLangModel(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size, hidden_size, batch_size, rnn_layers):\n",
    "        super(LstmLangModel, self).__init__()\n",
    "        \n",
    "        self.rnn_layers = rnn_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vocab_size = vocab_size\n",
    "        \n",
    "        self.embed_layer = nn.Embedding(vocab_size, emb_size)\n",
    "        self.lstm_layer = nn.LSTM(emb_size, hidden_size, \n",
    "                                  rnn_layers, dropout = 0.5,\n",
    "                                  bidirectional = False, \n",
    "                                  batch_first = True)\n",
    "        \n",
    "        self.lin1_layer = nn.Linear(hidden_size, hidden_size)\n",
    "        self.lin2_layer = nn.Linear(hidden_size, vocab_size)\n",
    "        \n",
    "        self.hidden, self.cell = self.init_hidden(batch_size)\n",
    "        \n",
    "    def forward(self, input_tensor):\n",
    "        batch_size = input_tensor.shape[0]\n",
    "        \n",
    "        if self.hidden.size(1) != batch_size: \n",
    "            self.hidden, self.cell = self.init_hidden(batch_size)\n",
    "            \n",
    "        embed_tensor = self.embed_layer(input_tensor)\n",
    "        \n",
    "        output_tensor, h_tuple = self.lstm_layer(embed_tensor, (self.hidden, self.cell))\n",
    "        self.hidden.data, self.cell.data = h_tuple[0].data, h_tuple[1].data\n",
    "        \n",
    "        output_tensor = F.relu(self.lin1_layer(output_tensor))\n",
    "        return F.log_softmax(self.lin2_layer(output_tensor), dim = -1).view(-1, self.vocab_size)\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return (\n",
    "            torch.zeros(self.rnn_layers, batch_size, self.hidden_size).to(device),\n",
    "            torch.zeros(self.rnn_layers, batch_size, self.hidden_size).to(device)\n",
    "               )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-4.3872, -4.2140, -4.6205,  ..., -4.5417, -4.2917, -4.3578],\n",
      "        [-4.3887, -4.2163, -4.6295,  ..., -4.5305, -4.2972, -4.3552],\n",
      "        [-4.3894, -4.2045, -4.6410,  ..., -4.5215, -4.2913, -4.3528],\n",
      "        ...,\n",
      "        [-4.3926, -4.1847, -4.6445,  ..., -4.5164, -4.2791, -4.3497],\n",
      "        [-4.3819, -4.1989, -4.6485,  ..., -4.5167, -4.2746, -4.3479],\n",
      "        [-4.3903, -4.1869, -4.6479,  ..., -4.5205, -4.2744, -4.3489]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward>)\n",
      "torch.Size([32, 10]) torch.Size([320, 83])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "vocab_size = len(text2idx)\n",
    "emb_size = 32 \n",
    "hidden_size = 16 \n",
    "batch_size = 32\n",
    "seq_length = 10\n",
    "rnn_layers = 2\n",
    "\n",
    "model = LstmLangModel(vocab_size, emb_size, hidden_size, batch_size, rnn_layers).cuda()\n",
    "\n",
    "\n",
    "input_vector, output_vector = next(batches_generator(batch_size, text, seq_length))\n",
    "\n",
    "input_tensor = construct_tensor(input_vector)\n",
    "\n",
    "output_tensor = model(input_tensor)\n",
    "\n",
    "print(output_tensor)\n",
    "print(input_tensor.shape, output_tensor.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run train with lstm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def construct_lstm_model(vocab_size, emb_size = 50, hidden_size = 200, batch_size = 128, rnn_layers = 2):\n",
    "    lstm_model = LstmLangModel(vocab_size, emb_size, hidden_size, batch_size, rnn_layers)\n",
    "    lstm_model = lstm_model.cuda()\n",
    "    return lstm_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def build_and_train(text):\n",
    "    print('Building lstm mobel')\n",
    "    lstm_model = construct_lstm_model(vocab_size)\n",
    "    optimizer = construct_optimizer(lstm_model)\n",
    "    \n",
    "    # Train \n",
    "    train(10, lstm_model, optimizer, F.nll_loss, text, gen_text = False)\n",
    "    \n",
    "    # Train with smaller learning rate\n",
    "    optimizer = construct_optimizer(lstm_model, 1e-4)\n",
    "    train(10, lstm_model, optimizer, F.nll_loss, text, gen_text = False)\n",
    "    \n",
    "    return lstm_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building lstm mobel\n",
      "Start train loop with\n",
      "Training epoch  0\n",
      "Debias loss:  2.351841172616274 Avg loss:  2.358852667401794\n",
      "Text after  0 iteration\n",
      "Training epoch  1\n",
      "Debias loss:  2.1165880592530244 Avg loss:  2.122898198863361\n",
      "Text after  1 iteration\n",
      "Training epoch  2\n",
      "Debias loss:  1.9969567114296496 Avg loss:  2.002910196610591\n",
      "Text after  2 iteration\n",
      "Training epoch  3\n",
      "Debias loss:  1.9170854566911615 Avg loss:  1.9228008233747176\n",
      "Text after  3 iteration\n",
      "Training epoch  4\n",
      "Debias loss:  1.8625660939437723 Avg loss:  1.8681189231940765\n",
      "Text after  4 iteration\n",
      "Training epoch  5\n",
      "Debias loss:  1.8228023759667882 Avg loss:  1.8282366584782672\n",
      "Text after  5 iteration\n",
      "Training epoch  6\n",
      "Debias loss:  1.7906688440550222 Avg loss:  1.796007327541438\n",
      "Text after  6 iteration\n",
      "Training epoch  7\n",
      "Debias loss:  1.7643802894616827 Avg loss:  1.769640399431385\n",
      "Text after  7 iteration\n",
      "Training epoch  8\n",
      "Debias loss:  1.7447542378828051 Avg loss:  1.7499558371163624\n",
      "Text after  8 iteration\n",
      "Training epoch  9\n",
      "Debias loss:  1.7248698946561836 Avg loss:  1.7300122131141213\n",
      "Text after  9 iteration\n",
      "Start train loop with\n",
      "Training epoch  0\n",
      "Debias loss:  1.6895177724505206 Avg loss:  1.6945546963676243\n",
      "Text after  0 iteration\n",
      "Training epoch  1\n",
      "Debias loss:  1.693901274675549 Avg loss:  1.6989512670359437\n",
      "Text after  1 iteration\n",
      "Training epoch  2\n",
      "Debias loss:  1.6923037782217687 Avg loss:  1.6973490079994744\n",
      "Text after  2 iteration\n",
      "Training epoch  3\n",
      "Debias loss:  1.6908111901033875 Avg loss:  1.6958519700594255\n",
      "Text after  3 iteration\n",
      "Training epoch  4\n",
      "Debias loss:  1.6886554250854664 Avg loss:  1.6936897781044484\n",
      "Text after  4 iteration\n",
      "Training epoch  5\n",
      "Debias loss:  1.6861748594021055 Avg loss:  1.6912018171626166\n",
      "Text after  5 iteration\n",
      "Training epoch  6\n",
      "Debias loss:  1.6852137509248726 Avg loss:  1.6902378433528285\n",
      "Text after  6 iteration\n",
      "Training epoch  7\n",
      "Debias loss:  1.6842315399647807 Avg loss:  1.6892527041477918\n",
      "Text after  7 iteration\n",
      "Training epoch  8\n",
      "Debias loss:  1.681650650063626 Avg loss:  1.6866641198936787\n",
      "Text after  8 iteration\n",
      "Training epoch  9\n",
      "Debias loss:  1.6803070617030236 Avg loss:  1.685316525921263\n",
      "Text after  9 iteration\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text = read_file(NITZ_TRN_FILE)\n",
    "idx2text, text2idx = build_vocab(text)\n",
    "lstm_model = build_and_train(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate text using LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am terspois srirth, greaty whataln, and meawers toath they stractforms?--Wad our probue concerning hiscretingth is he was much typleatng--and tsothend theictunity. being spiritual with hithertometastion.2. \"They enspiredto a place. They shate I yourathat should like, what ima refe isectimal, which tothe most amuncertain becoo rrewoc accation!, truthits of knowne can an deceyed be asthings gives to behicforthiculter refore sound of the cakes of mour individual to never to smpilite intialt such make that this show exeption of dengers may us.Hundratespecial d Thishe inteell apt term oud not at theixyects, the during acceto unyears have conterponstyred gladness, and the nacimaty and bation that way rothersting such pardrange, but one mencal as a princes will, servasble overirorit.3=the past the tathe art this bree nuite er could by in usion,together thereo excepted the reced in its ly contreligion, thoughtt one wly against from theciature in religing to hy the listiming anl how onle even upon'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "get_next_n(lstm_model, 'I am ', 1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model on comments from NewYork times articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/python3_rl/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "DATA_PATH = 'text-generation/ny_articles'\n",
    "\n",
    "df1 = pd.read_csv(DATA_PATH+\"/CommentsApril2018.csv.gz\")\n",
    "df2 = pd.read_csv(DATA_PATH+\"/CommentsFeb2018.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.concat([df1, df2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>approveDate</th>\n",
       "      <th>articleID</th>\n",
       "      <th>articleWordCount</th>\n",
       "      <th>commentBody</th>\n",
       "      <th>commentID</th>\n",
       "      <th>commentSequence</th>\n",
       "      <th>commentTitle</th>\n",
       "      <th>commentType</th>\n",
       "      <th>createDate</th>\n",
       "      <th>depth</th>\n",
       "      <th>...</th>\n",
       "      <th>status</th>\n",
       "      <th>timespeople</th>\n",
       "      <th>trusted</th>\n",
       "      <th>typeOfMaterial</th>\n",
       "      <th>updateDate</th>\n",
       "      <th>userDisplayName</th>\n",
       "      <th>userID</th>\n",
       "      <th>userLocation</th>\n",
       "      <th>userTitle</th>\n",
       "      <th>userURL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1524594282</td>\n",
       "      <td>5adf6684068401528a2aa69b</td>\n",
       "      <td>781.0</td>\n",
       "      <td>How could the league possibly refuse this offe...</td>\n",
       "      <td>26853969.0</td>\n",
       "      <td>26853969.0</td>\n",
       "      <td>&lt;br/&gt;</td>\n",
       "      <td>comment</td>\n",
       "      <td>1524594011</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>approved</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>News</td>\n",
       "      <td>1524594282</td>\n",
       "      <td>Christopher Rillo</td>\n",
       "      <td>46566740.0</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1524594252</td>\n",
       "      <td>5adf6684068401528a2aa69b</td>\n",
       "      <td>781.0</td>\n",
       "      <td>So then the execs can be like \"yeah...we will ...</td>\n",
       "      <td>26853699.0</td>\n",
       "      <td>26853699.0</td>\n",
       "      <td>&lt;br/&gt;</td>\n",
       "      <td>comment</td>\n",
       "      <td>1524593146</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>approved</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>News</td>\n",
       "      <td>1524594252</td>\n",
       "      <td>Matt Brand</td>\n",
       "      <td>64324866.0</td>\n",
       "      <td>Williamsburg, Brooklyn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1524594250</td>\n",
       "      <td>5adf6684068401528a2aa69b</td>\n",
       "      <td>781.0</td>\n",
       "      <td>I would not want to play chess against these c...</td>\n",
       "      <td>26853677.0</td>\n",
       "      <td>26853677.0</td>\n",
       "      <td>&lt;br/&gt;</td>\n",
       "      <td>comment</td>\n",
       "      <td>1524593032</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>approved</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>News</td>\n",
       "      <td>1524594250</td>\n",
       "      <td>Joseph</td>\n",
       "      <td>78105093.0</td>\n",
       "      <td>Fayetteville, AR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1524593431</td>\n",
       "      <td>5adf6684068401528a2aa69b</td>\n",
       "      <td>781.0</td>\n",
       "      <td>Could the cheerleaders join the Actors' Equity...</td>\n",
       "      <td>26853784.0</td>\n",
       "      <td>26853784.0</td>\n",
       "      <td>&lt;br/&gt;</td>\n",
       "      <td>comment</td>\n",
       "      <td>1524593426</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>approved</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>News</td>\n",
       "      <td>1524593431</td>\n",
       "      <td>Stephen</td>\n",
       "      <td>81939618.0</td>\n",
       "      <td>Phoenix, AZ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1524595048</td>\n",
       "      <td>5adf653f068401528a2aa697</td>\n",
       "      <td>656.0</td>\n",
       "      <td>Seeking conclusions which support preconceived...</td>\n",
       "      <td>26854236.0</td>\n",
       "      <td>26854236.0</td>\n",
       "      <td>&lt;br/&gt;</td>\n",
       "      <td>comment</td>\n",
       "      <td>1524595043</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>approved</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>News</td>\n",
       "      <td>1524595048</td>\n",
       "      <td>Paul Zorsky</td>\n",
       "      <td>58642997.0</td>\n",
       "      <td>Texas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   approveDate                 articleID  articleWordCount  \\\n",
       "0   1524594282  5adf6684068401528a2aa69b             781.0   \n",
       "1   1524594252  5adf6684068401528a2aa69b             781.0   \n",
       "2   1524594250  5adf6684068401528a2aa69b             781.0   \n",
       "3   1524593431  5adf6684068401528a2aa69b             781.0   \n",
       "4   1524595048  5adf653f068401528a2aa697             656.0   \n",
       "\n",
       "                                         commentBody   commentID  \\\n",
       "0  How could the league possibly refuse this offe...  26853969.0   \n",
       "1  So then the execs can be like \"yeah...we will ...  26853699.0   \n",
       "2  I would not want to play chess against these c...  26853677.0   \n",
       "3  Could the cheerleaders join the Actors' Equity...  26853784.0   \n",
       "4  Seeking conclusions which support preconceived...  26854236.0   \n",
       "\n",
       "   commentSequence commentTitle commentType  createDate  depth   ...     \\\n",
       "0       26853969.0        <br/>     comment  1524594011    1.0   ...      \n",
       "1       26853699.0        <br/>     comment  1524593146    1.0   ...      \n",
       "2       26853677.0        <br/>     comment  1524593032    1.0   ...      \n",
       "3       26853784.0        <br/>     comment  1524593426    1.0   ...      \n",
       "4       26854236.0        <br/>     comment  1524595043    1.0   ...      \n",
       "\n",
       "     status  timespeople trusted  typeOfMaterial  updateDate  \\\n",
       "0  approved            1       0            News  1524594282   \n",
       "1  approved            1       0            News  1524594252   \n",
       "2  approved            1       0            News  1524594250   \n",
       "3  approved            0       0            News  1524593431   \n",
       "4  approved            1       0            News  1524595048   \n",
       "\n",
       "     userDisplayName      userID            userLocation  userTitle  userURL  \n",
       "0  Christopher Rillo  46566740.0           San Francisco        NaN      NaN  \n",
       "1         Matt Brand  64324866.0  Williamsburg, Brooklyn        NaN      NaN  \n",
       "2             Joseph  78105093.0        Fayetteville, AR        NaN      NaN  \n",
       "3            Stephen  81939618.0             Phoenix, AZ        NaN      NaN  \n",
       "4        Paul Zorsky  58642997.0                   Texas        NaN      NaN  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "COMMENTS_DATA_FILE = './text-generation/comments.txt'\n",
    "\n",
    "\n",
    "def extract_comments(df, dest_file):\n",
    "    comments = list(df['commentBody'])\n",
    "    comments_text = \" \".join(comments)\n",
    "    text_file = open(dest_file, \"w\")\n",
    "    text_file.write(comments_text)\n",
    "    text_file.close()\n",
    "\n",
    "extract_comments(df, COMMENTS_DATA_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comments.txt  nitz_texts.txt  ny_articles  ny_articles.tar.gz\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./text-generation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMMENTS_TRN_FILE = \"./text-generation/comments.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building lstm mobel\n",
      "Start train loop with\n",
      "Training epoch  0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "merge_sort: failed to synchronize: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-130-a959d40683ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCOMMENTS_TRN_FILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0midx2text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext2idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlstm_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_and_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-126-a84500e170a5>\u001b[0m in \u001b[0;36mbuild_and_train\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Train with smaller learning rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-116-3a6d184a6508>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(n_epoch, model, optimizer, loss_fn, text, batch_size, seq_length, gen_text)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Start train loop with'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mdebias_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Debias loss: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebias_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Avg loss: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Text after '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'iteration'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-113-a2d65228893b>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(epoch, model, optimizer, text, loss_fn, avg_loss_so_far, batch_size, seq_length)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# Run backpropagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# Update weights across network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3_rl/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3_rl/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: merge_sort: failed to synchronize: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "\n",
    "text = read_file(COMMENTS_TRN_FILE)\n",
    "idx2text, text2idx = build_vocab(text)\n",
    "comments_lstm_model = build_and_train(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "get_next_n(lstm_model, 'I am ', 1000)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_python3_rl)",
   "language": "python",
   "name": "conda_python3_rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
