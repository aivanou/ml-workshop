{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Recognize named entities on Twitter with LSTMs\n",
    "\n",
    "In this workshop, you will use a recurrent neural network to solve Named Entity Recognition (NER) problem. NER is a common task in natural language processing systems. It serves for extraction such entities from the text as persons, organizations, locations, etc. In this task you will experiment to recognize named entities from Twitter.\n",
    "\n",
    "For example, we want to extract persons' and organizations' names from the text. Than for the input text:\n",
    "\n",
    "    Donald Trump is the president of the United States\n",
    "\n",
    "a NER model needs to provide the following sequence of tags:\n",
    "\n",
    "    B-PER I-PER   O O O O O   B-COUNTRY  I-COUNTRY\n",
    "\n",
    "Where *B-* and *I-* prefixes stand for the beginning and inside of the entity, while *O* stands for out of tag or no tag. Markup with the prefix scheme is called *BIO markup*. This markup is introduced for distinguishing of consequent entities with similar types.\n",
    "\n",
    "A solution of the task will be based on neural networks, particularly, on Bi-Directional Long Short-Term Memory Networks (Bi-LSTMs).\n",
    "\n",
    "### Libraries\n",
    "\n",
    "For this task you will need the following libraries:\n",
    " - [Pytorch](https://pytorch.org/docs/stable/index.html) — an open-source software library for Machine Intelligence.\n",
    " - [Numpy](http://www.numpy.org) — a package for scientific computing.\n",
    "\n",
    "Add tutorial link to Pytorch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries and download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ner/train.txt is already downloaded.\n",
      "File ner/test.txt is already downloaded.\n",
      "File ner/validation.txt is already downloaded.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "from common.evaluation import precision_recall_f1\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import common.workshop as workshop\n",
    "\n",
    "workshop.download_ner_generation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup execution device\n",
    "\n",
    "Note: since this is hevy computational task, we need to use GPU, make sure that the cell below outputs 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Execution device:',device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.txt  train.txt  validation.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./ner/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR=\"ner\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read file \n",
    "\n",
    "Read data from file and change replace users and urls with tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_path):\n",
    "    tokens = []\n",
    "    tags = []\n",
    "    \n",
    "    tweet_tokens = []\n",
    "    tweet_tags = []\n",
    "    for line in open(file_path, encoding='utf-8'):\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            if tweet_tokens:\n",
    "                tokens.append(tweet_tokens)\n",
    "                tags.append(tweet_tags)\n",
    "            tweet_tokens = []\n",
    "            tweet_tags = []\n",
    "        else:\n",
    "            token, tag = line.split()\n",
    "            # Replace all urls with <URL> token\n",
    "            # Replace all users with <USR> token\n",
    "\n",
    "            # your code\n",
    "            \n",
    "            tweet_tokens.append(token)\n",
    "            tweet_tags.append(tag)\n",
    "            \n",
    "    return tokens, tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can load three separate parts of the dataset:\n",
    " - *train* data for training the model;\n",
    " - *validation* data for evaluation and hyperparameters tuning;\n",
    " - *test* data for final evaluation of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_tokens, train_tags = read_data(DATA_DIR + '/train.txt')\n",
    "validation_tokens, validation_tags = read_data(DATA_DIR + '/validation.txt')\n",
    "test_tokens, test_tags = read_data(DATA_DIR + '/test.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['RT', '<USR>', ':', 'Online', 'ticket', 'sales', 'for', 'Ghostland', 'Observatory', 'extended', 'until', '6', 'PM', 'EST', 'due', 'to', 'high', 'demand', '.', 'Get', 'them', 'before', 'they', 'sell', 'out', '...'], ['Apple', 'MacBook', 'Pro', 'A1278', '13.3', '\"', 'Laptop', '-', 'MD101LL/A', '(', 'June', ',', '2012', ')', '-', 'Full', 'read', 'by', 'eBay', '<URL>', '<URL>']]\n"
     ]
    }
   ],
   "source": [
    "print (train_tokens[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lest take a look at our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT\tO\n",
      "<USR>\tO\n",
      ":\tO\n",
      "Online\tO\n",
      "ticket\tO\n",
      "sales\tO\n",
      "for\tO\n",
      "Ghostland\tB-musicartist\n",
      "Observatory\tI-musicartist\n",
      "extended\tO\n",
      "until\tO\n",
      "6\tO\n",
      "PM\tO\n",
      "EST\tO\n",
      "due\tO\n",
      "to\tO\n",
      "high\tO\n",
      "demand\tO\n",
      ".\tO\n",
      "Get\tO\n",
      "them\tO\n",
      "before\tO\n",
      "they\tO\n",
      "sell\tO\n",
      "out\tO\n",
      "...\tO\n",
      "\n",
      "Apple\tB-product\n",
      "MacBook\tI-product\n",
      "Pro\tI-product\n",
      "A1278\tI-product\n",
      "13.3\tI-product\n",
      "\"\tI-product\n",
      "Laptop\tI-product\n",
      "-\tI-product\n",
      "MD101LL/A\tI-product\n",
      "(\tO\n",
      "June\tO\n",
      ",\tO\n",
      "2012\tO\n",
      ")\tO\n",
      "-\tO\n",
      "Full\tO\n",
      "read\tO\n",
      "by\tO\n",
      "eBay\tB-company\n",
      "<URL>\tO\n",
      "<URL>\tO\n",
      "\n",
      "Happy\tO\n",
      "Birthday\tO\n",
      "<USR>\tO\n",
      "!\tO\n",
      "May\tO\n",
      "Allah\tB-person\n",
      "s.w.t\tO\n",
      "bless\tO\n",
      "you\tO\n",
      "with\tO\n",
      "goodness\tO\n",
      "and\tO\n",
      "happiness\tO\n",
      ".\tO\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(3):\n",
    "    for token, tag in zip(train_tokens[i], train_tags[i]):\n",
    "        print('%s\\t%s' % (token, tag))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dictionaries\n",
    "\n",
    "To train a neural network, we will use two mappings: \n",
    "- {token}$\\to${token id}: address the row in embeddings matrix for the current token;\n",
    "- {tag}$\\to${tag id}: one-hot ground truth probability distribution vectors for computing the loss at the output of the network.\n",
    "\n",
    "Now you need to implement the function *build_dict* which will return {token or tag}$\\to${index} and vice versa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def build_dict(tokens_or_tags, special_tokens):\n",
    "    \"\"\"\n",
    "        tokens_or_tags: a list of lists of tokens or tags\n",
    "        special_tokens: some special tokens\n",
    "    \"\"\"\n",
    "    # Create a dictionary with default value 0\n",
    "    tok2idx = defaultdict(lambda: 0)\n",
    "    idx2tok = []\n",
    "    \n",
    "    # Create mappings from tokens (or tags) to indices and vice versa.\n",
    "    # Add special tokens (or tags) to the dictionaries.\n",
    "    # The first special token must have index 0.\n",
    "    \n",
    "    # Mapping tok2idx should contain each token or tag only once. \n",
    "    # To do so, you should extract unique tokens/tags from the tokens_or_tags variable\n",
    "    # and then index them (for example, you can add them into the list idx2tok\n",
    "    # and for each token/tag save the index into tok2idx).\n",
    "    \n",
    "    idx = 0\n",
    "\n",
    "    # your code\n",
    "    \n",
    "    return tok2idx, idx2tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "special_tokens = ['<UNK>', '<PAD>']\n",
    "special_tags = ['O']\n",
    "\n",
    "# Create dictionaries \n",
    "token2idx, idx2token = build_dict(train_tokens + validation_tokens, special_tokens)\n",
    "tag2idx, idx2tag = build_dict(train_tags, special_tags)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next additional functions will help you to create the mapping between tokens and ids for a sentence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words2idxs(tokens_list):\n",
    "    return [token2idx[word] for word in tokens_list]\n",
    "\n",
    "def tags2idxs(tags_list):\n",
    "    return [tag2idx[tag] for tag in tags_list]\n",
    "\n",
    "def idxs2words(idxs):\n",
    "    return [idx2token[idx] for idx in idxs]\n",
    "\n",
    "def idxs2tags(idxs):\n",
    "    return [idx2tag[idx] for idx in idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate batches\n",
    "\n",
    "Neural Networks are usually trained with batches. It means that weight updates of the network are based on several sequences at every single time. The tricky part is that all sequences within a batch need to have the same length. So we will pad them with a special `<PAD>` token. It is also a good practice to provide RNN with sequence lengths, so it can skip computations for padding parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This function generates batches of input data.\n",
    "# Since each train example has variable length we need to pad some of them to make sure\n",
    "# that each train data vector has the same size\n",
    "def batches_generator(batch_size, tokens, tags,\n",
    "                      shuffle=True, allow_smaller_last_batch=True):\n",
    "    \"\"\"Generates padded batches of tokens and tags.\"\"\"\n",
    "    \n",
    "    n_samples = len(tokens)\n",
    "    \n",
    "    if shuffle:\n",
    "        order = np.random.permutation(n_samples)\n",
    "    else:\n",
    "        order = np.arange(n_samples)\n",
    "\n",
    "    # number of batches\n",
    "    n_batches = n_samples // batch_size\n",
    "    # the last batch has smaller length, if our network can handle different batch sizes, we can also utilize the last batch\n",
    "    if allow_smaller_last_batch and n_samples % batch_size:\n",
    "        n_batches += 1\n",
    "    \n",
    "    for k in range(n_batches):\n",
    "        batch_start = k * batch_size\n",
    "        batch_end = min((k + 1) * batch_size, n_samples)\n",
    "        \n",
    "        current_batch_size = batch_end - batch_start\n",
    "        \n",
    "        x_list = []\n",
    "        y_list = []\n",
    "        \n",
    "        # max_len_token will be the length of the input sequence for each train example\n",
    "        max_len_token = 0\n",
    "        for idx in order[batch_start: batch_end]:\n",
    "            x_list.append(words2idxs(tokens[idx]))\n",
    "            y_list.append(tags2idxs(tags[idx]))\n",
    "            max_len_token = max(max_len_token, len(tags[idx]))\n",
    "            \n",
    "        # Initialize x as matrix of idx('<PAD>')\n",
    "        x = np.ones([current_batch_size, max_len_token], dtype=np.int32) * token2idx['<PAD>']\n",
    "        # Initialize y as matrix of idx('O')\n",
    "        y = np.ones([current_batch_size, max_len_token], dtype=np.int32) * tag2idx['O']\n",
    "        lengths = np.zeros(current_batch_size, dtype=np.int32)\n",
    "        \n",
    "        # Iterate through batch size and assign variable sequence to each train example.\n",
    "        # E.g. x[n, :m] = arr (arr should have length of m) - means: \n",
    "        # n'th row first m characters will be assigned values \n",
    "        for current_batch_num in range(current_batch_size):\n",
    "            curr_example_length = len(x_list[current_batch_num])\n",
    "            x[current_batch_num, :curr_example_length] = x_list[current_batch_num]\n",
    "            lengths[current_batch_num] = curr_example_length\n",
    "            y[current_batch_num, :curr_example_length] = y_list[current_batch_num]\n",
    "            \n",
    "        yield x, y, lengths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 23) (10, 23)\n"
     ]
    }
   ],
   "source": [
    "# check the generator\n",
    "\n",
    "batch_size= 10\n",
    "x,y, _ = next(batches_generator(batch_size, train_tokens, train_tags))\n",
    "\n",
    "print(x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a recurrent neural network\n",
    "\n",
    "This is the most important part of the assignment. Here we will specify the network architecture based on Pytorch building blocks. It's fun and easy as a lego constructor! We will create an LSTM network which will produce probability distribution over tags for each token in a sentence. To take into account both right and left contexts of the token, we will use Bi-Directional LSTM (Bi-LSTM). Dense layer will be used on top to perform tag classification.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: explain what architecture needs to be built, and provide documentation to corresponding blocks\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class BiLstm(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, n_hidden, n_output):\n",
    "        # Invoke the constructor\n",
    "        super(BiLstm, self).__init__()\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_output = n_output\n",
    "        \n",
    "        # simple embedding layer, that will be learned\n",
    "        self.embed_layer = nn.Embedding(vocab_size, embed_size)\n",
    "        \n",
    "        # bidirectional 2 layer LSTM \n",
    "        self.lstm_layer = nn.LSTM(embed_size, n_hidden,\n",
    "                                  num_layers = 2, batch_first = True, \n",
    "                                  bidirectional = True)\n",
    "        \n",
    "        # linear layer to produce outputs\n",
    "        self.linear_layer = nn.Linear(2*n_hidden, n_output)\n",
    "        \n",
    "\n",
    "    # input_tensor - shape (batch_size, seq_length)\n",
    "    # hidden - pair of tensors of shape (batch_size, hidden_size)\n",
    "    def forward(self, input_tensor, seq_length, batch_size):\n",
    "\n",
    "        # e_tensor - (batch_size, seq_length, embed_size)\n",
    "        e_tensor = self.embed_layer(input_tensor)\n",
    "              \n",
    "        # execute lstm layer\n",
    "        lstm_out, _ = self.lstm_layer(e_tensor)\n",
    "\n",
    "        \n",
    "        # transfor output to the 2d matrix of shape (batch_size * seq_length, 2*hidden_size)\n",
    "        # since it is bidirectional network there is double size of hidden parameters\n",
    "        output_tensor = lstm_out.contiguous().view(-1, 2 * self.n_hidden)\n",
    "        # execute linear layer\n",
    "        output_tensor = self.linear_layer(output_tensor)\n",
    "        \n",
    "        return output_tensor\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Constructs pytorch tensor from numpy array\n",
    "def construct_pytorch_tensor(numpy_tensor):\n",
    "    tensor = torch.from_numpy(numpy_tensor).long()\n",
    "    # Send tensor to the device\n",
    "    tensor = tensor.to(device)\n",
    "    return tensor\n",
    "\n",
    "\n",
    "def construct_model(vocab_size, embed_size, hidden_size, output_size):\n",
    "    bi_nn = BiLstm(vocab_size=vocab_size, embed_size=embed_size, \n",
    "                 n_hidden=hidden_size, n_output=output_size)\n",
    "    bi_nn = bi_nn.to(device)\n",
    "    return bi_nn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the network\n",
    "\n",
    "lest test the created network. Play with parameters to see how do the affect input and output tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 21])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pdb\n",
    "\n",
    "vocab_size = len(idx2token)\n",
    "n_tags = len(idx2tag)\n",
    "n_input = 100\n",
    "n_hidden = 40\n",
    "batch_size = 4\n",
    "embed_size = 30\n",
    "\n",
    "x,y, l = next(batches_generator(batch_size, train_tokens, train_tags))\n",
    "\n",
    "# seq length\n",
    "model_seq_length = x.shape[1]\n",
    "\n",
    "input_tensor = construct_pytorch_tensor(x) # construct input tensor\n",
    "\n",
    "target_tensor = construct_pytorch_tensor(y) # construct target tensor\n",
    "\n",
    "bi_nn = construct_model(vocab_size, embed_size, n_hidden, n_tags) # init model\n",
    "\n",
    "output_tensor = bi_nn(input_tensor, model_seq_length, batch_size) # execute forward\n",
    "print(output_tensor.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "below defined evaluation functions.\n",
    "\n",
    "We use precision/recall metric and F1 score to determine the performance.\n",
    "\n",
    "Additional resources:\n",
    "\n",
    "[precision/recall](https://en.wikipedia.org/wiki/Precision_and_recall)\n",
    "\n",
    "[f1score](https://skymind.ai/wiki/accuracy-precision-recall-f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_on_data(model, tokens, tags):\n",
    "    y_true_indx = []\n",
    "    y_pred_indx = []\n",
    "    batch_size = 32\n",
    "    \n",
    "    for i, (x, y, _) in enumerate(batches_generator(batch_size, tokens, tags)):\n",
    "        input_tensor = torch.from_numpy(x).long().to(device)\n",
    "        taget_tensor = torch.from_numpy(y).long().to(device)\n",
    "        \n",
    "        batch_size = x.shape[0]\n",
    "        seq_length = x.shape[1]\n",
    "\n",
    "        output_tensor = model(input_tensor, seq_length, batch_size)\n",
    "        output_tensor = F.softmax(output_tensor, dim = 1)\n",
    "        _, output_inds = output_tensor.max(dim = 1)\n",
    "        \n",
    "        output_inds = output_inds.long()\n",
    "        \n",
    "        y_true_indx_batch = list(taget_tensor.cpu().numpy().reshape(-1))\n",
    "        y_pred_indx_batch = list(output_inds.cpu().detach().numpy().reshape(-1))\n",
    "        y_true_indx = y_true_indx + y_true_indx_batch\n",
    "        y_pred_indx = y_pred_indx + y_pred_indx_batch\n",
    "        \n",
    "    y_true = [idx2tag[idx] for idx in y_true_indx]\n",
    "    y_pred = [idx2tag[idx] for idx in y_pred_indx]\n",
    "    \n",
    "    precision_recall_f1(y_true, y_pred, print_results=True, short_report=True)\n",
    "    \n",
    "def evaluate(model):\n",
    "    # For evaluation we do not need to update gradients and compute derivatives\n",
    "    with torch.no_grad():\n",
    "        print('Evaluation on train set')\n",
    "        evaluate_on_data(model, train_tokens, train_tags)\n",
    "        print('Evaluation on validation set')\n",
    "        evaluate_on_data(model, validation_tokens, validation_tags)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train loop\n",
    "\n",
    "Below defined the train loop for a single epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(model, optimizer, loss_fn, batch_size = 32):\n",
    "    for batch_num, (input_data, target_data, _) in enumerate(batches_generator(batch_size, train_tokens, train_tags)):\n",
    "        \n",
    "        # The last batch can be smaller than others\n",
    "        train_batch_size = input_data.shape[0]\n",
    "        # Since each batch has different sequence length we need to update the variable for each batch\n",
    "        train_seq_length = input_data.shape[1]\n",
    "\n",
    "        input_tensor = construct_pytorch_tensor(input_data)\n",
    "        target_tensor = construct_pytorch_tensor(target_data)\n",
    "        \n",
    "        # zero out the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # get the output sequence from the input and the initial hidden and cell states\n",
    "        output_tensor = model(input_tensor, train_seq_length, train_batch_size).to(device)\n",
    "    \n",
    "        # we need to calculate the loss across all batches, so we have to flat the targets tensor\n",
    "#         pdb.set_trace()\n",
    "        target_tensor = target_tensor.view((train_seq_length*train_batch_size, -1)).squeeze(dim=1)\n",
    "        \n",
    "        # calculate the loss\n",
    "        loss = loss_fn(output_tensor, target_tensor)\n",
    "\n",
    "        # calculate the gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # update the parameters of the model\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main train loop\n",
    "\n",
    "We will be bu using precision/recall metric and F1 score as evaluation. Precision/recall is very useful metric that shows how well classification task performs. We can split our classification results on four categories:\n",
    "\n",
    "    Lest say that our target_output is the true output of data, while predicted_output is the predicted output of our network. In this case:\n",
    "\n",
    "    True positives - predicted_output that are labeled as positives, and target_output are actually positive\n",
    "    True negatives - predicted_output that are labeled as negatives, and target_output are actually negatives\n",
    "    False positives - predicted_output that are labeled as negatives, and target_output are actually positives\n",
    "    False negatives - predicted_output that are labeled as positives, and target_output are actually negatives\n",
    "    \n",
    "    wheer positives - predicted sucsesfully, negatives - predicted unsucsessfully\n",
    "    \n",
    "In this case, precision and recall are defined as:\n",
    "\n",
    "![title](images/precision_recall.png)\n",
    "\n",
    "We also can combine these two metrics into a single one, called F1 score:\n",
    "\n",
    "![title](images/f1-score.jpg)\n",
    "\n",
    "\n",
    "Additional materials:\n",
    "\n",
    "[PrecisionRecall](https://towardsdatascience.com/beyond-accuracy-precision-and-recall-3da06bea9f6c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch:  0\n",
      "Evaluation on train set\n",
      "processed 180520 tokens with 4489 phrases; found: 1021 phrases; correct: 663.\n",
      "\n",
      "precision:  64.94%; recall:  14.77%; F1:  24.07\n",
      "\n",
      "Evaluation on validation set\n",
      "processed 22328 tokens with 537 phrases; found: 98 phrases; correct: 56.\n",
      "\n",
      "precision:  57.14%; recall:  10.43%; F1:  17.64\n",
      "\n",
      "Starting epoch:  1\n",
      "Evaluation on train set\n",
      "processed 179496 tokens with 4489 phrases; found: 4038 phrases; correct: 2525.\n",
      "\n",
      "precision:  62.53%; recall:  56.25%; F1:  59.22\n",
      "\n",
      "Evaluation on validation set\n",
      "processed 22248 tokens with 537 phrases; found: 365 phrases; correct: 153.\n",
      "\n",
      "precision:  41.92%; recall:  28.49%; F1:  33.92\n",
      "\n",
      "Starting epoch:  2\n",
      "Evaluation on train set\n",
      "processed 178815 tokens with 4489 phrases; found: 4635 phrases; correct: 3432.\n",
      "\n",
      "precision:  74.05%; recall:  76.45%; F1:  75.23\n",
      "\n",
      "Evaluation on validation set\n",
      "processed 22512 tokens with 537 phrases; found: 473 phrases; correct: 162.\n",
      "\n",
      "precision:  34.25%; recall:  30.17%; F1:  32.08\n",
      "\n",
      "Starting epoch:  3\n",
      "Evaluation on train set\n",
      "processed 179766 tokens with 4489 phrases; found: 4632 phrases; correct: 4116.\n",
      "\n",
      "precision:  88.86%; recall:  91.69%; F1:  90.25\n",
      "\n",
      "Evaluation on validation set\n",
      "processed 22448 tokens with 537 phrases; found: 507 phrases; correct: 180.\n",
      "\n",
      "precision:  35.50%; recall:  33.52%; F1:  34.48\n",
      "\n",
      "Starting epoch:  4\n",
      "Evaluation on train set\n",
      "processed 179796 tokens with 4489 phrases; found: 4508 phrases; correct: 4341.\n",
      "\n",
      "precision:  96.30%; recall:  96.70%; F1:  96.50\n",
      "\n",
      "Evaluation on validation set\n",
      "processed 22240 tokens with 537 phrases; found: 457 phrases; correct: 169.\n",
      "\n",
      "precision:  36.98%; recall:  31.47%; F1:  34.00\n",
      "\n",
      "Starting epoch:  5\n",
      "Evaluation on train set\n",
      "processed 179583 tokens with 4489 phrases; found: 4517 phrases; correct: 4451.\n",
      "\n",
      "precision:  98.54%; recall:  99.15%; F1:  98.85\n",
      "\n",
      "Evaluation on validation set\n",
      "processed 22616 tokens with 537 phrases; found: 494 phrases; correct: 177.\n",
      "\n",
      "precision:  35.83%; recall:  32.96%; F1:  34.34\n",
      "\n",
      "Starting epoch:  6\n",
      "Evaluation on train set\n",
      "processed 179863 tokens with 4489 phrases; found: 4496 phrases; correct: 4459.\n",
      "\n",
      "precision:  99.18%; recall:  99.33%; F1:  99.25\n",
      "\n",
      "Evaluation on validation set\n",
      "processed 22336 tokens with 537 phrases; found: 463 phrases; correct: 181.\n",
      "\n",
      "precision:  39.09%; recall:  33.71%; F1:  36.20\n",
      "\n",
      "Starting epoch:  7\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-876ea742cdd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Starting epoch: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-857ae98e710f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, loss_fn, batch_size)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# calculate the gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# update the parameters of the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3_rl/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3_rl/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# number of epoch to train\n",
    "n_epoch = 10\n",
    "\n",
    "# size of the hidden layer\n",
    "hidden_size = 256\n",
    "\n",
    "# batch size of input\n",
    "batch_size = 32\n",
    "\n",
    "# embedding size\n",
    "embed_size = 256\n",
    "\n",
    "# size of output vector on each timestamp\n",
    "n_tags = len(idx2tag)\n",
    "\n",
    "# vocabulary size, it is needed to build embedding layer\n",
    "vocab_size = len(idx2token)\n",
    "\n",
    "\n",
    "model = construct_model(vocab_size, embed_size, hidden_size, n_tags) # init model\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005) # Adam optimizer\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss() # Cross entropy loss\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    print('Starting epoch: ', epoch)\n",
    "    train(model, optimizer, loss_function, batch_size)\n",
    "    \n",
    "    evaluate(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets try to use our model to some arbitrary data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Donald', 'Trump', 'is', 'the', 'president', 'of', 'United', 'States']]\n",
      "Input:  Donald Trump is the president of United States\n",
      "predicted tags:  ['B-person', 'I-person', 'O', 'O', 'B-facility', 'O', 'B-sportsteam', 'I-geo-loc']\n"
     ]
    }
   ],
   "source": [
    "# add your sentencies\n",
    "\n",
    "sentencies = ['Donald Trump is the president of United States']\n",
    "\n",
    "my_tokens = []\n",
    "my_tags = []\n",
    "\n",
    "for sentence in sentencies:\n",
    "    token_arr = sentence.split(' ')\n",
    "    my_tokens.append(token_arr)\n",
    "    my_tags.append(['O']*len(token_arr))\n",
    "\n",
    "print(my_tokens)\n",
    "\n",
    "for idx, (input_x,_,_) in enumerate(batches_generator(1, my_tokens, my_tags, shuffle= False)):\n",
    "    sentence = sentencies[idx]\n",
    "    input_tensor = torch.from_numpy(input_x).long().to(device)\n",
    "    batch_size = input_x.shape[0]\n",
    "    seq_length = input_x.shape[1]\n",
    "    output_tensor = model(input_tensor, seq_length, batch_size)\n",
    "\n",
    "    output_tensor = F.softmax(output_tensor, dim = 1)\n",
    "    _, output_inds = output_tensor.max(dim = 1)\n",
    "\n",
    "    output_inds = output_inds.long()\n",
    "\n",
    "    print('Input: ', sentence)\n",
    "    print('predicted tags: ', [idx2tag[ind] for ind in output_inds])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "\n",
    "So far we learned how to build mini batches, how to use word embeddings and how to use bidirectional RNNs. \n",
    "We reached decens score, but we always can do better. One improvement that can be done is to modify the loss function to not count padded tokens. But this will be left as a take home exercise.\n",
    "\n",
    "\n",
    "But this is just the begginnig and there is more to learn. The good places to start are:\n",
    "\n",
    "[fastai](https://www.fast.ai/)\n",
    "\n",
    "[AdvancedMLSpecialization](https://www.coursera.org/specializations/aml)\n",
    "\n",
    "[DeepLearningAI](https://www.deeplearning.ai/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_python3_rl)",
   "language": "python",
   "name": "conda_python3_rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
